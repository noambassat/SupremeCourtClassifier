{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/noambassat/SupremeCourtClassifier/blob/main/5_second_classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "390cb142-eebf-4813-b1d1-11047c243db4",
      "metadata": {
        "id": "390cb142-eebf-4813-b1d1-11047c243db4"
      },
      "source": [
        "# Embedding + first classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9E55EdbICO6k",
      "metadata": {
        "id": "9E55EdbICO6k"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoModel\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import cross_validate, cross_val_score, StratifiedKFold,train_test_split,cross_val_predict\n",
        "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score,make_scorer, accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from sklearn.metrics import precision_recall_curve, accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, make_scorer\n",
        "from sklearn.model_selection import cross_val_predict, cross_validate\n",
        "import joblib\n",
        "import ast\n",
        "import re\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5532189c-1b24-4839-87d4-7d1790cff00c",
      "metadata": {
        "id": "5532189c-1b24-4839-87d4-7d1790cff00c"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv(\"full_final_df.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "id": "hfULjZgfvLAH"
      },
      "id": "hfULjZgfvLAH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# פונקציה להמרת טקסט שמופיע כרשימה למחרוזת רגילה\n",
        "def convert_list_to_string(text):\n",
        "    if isinstance(text, str) and text.startswith(\"[\") and text.endswith(\"]\"):\n",
        "        try:\n",
        "            # מנסה להמיר את התוכן בתוך הסוגריים לרשימה אמיתית\n",
        "            text_list = ast.literal_eval(text)\n",
        "            # איחוד המחרוזות לרצף טקסט אחד\n",
        "            return ' '.join(text_list)\n",
        "        except (ValueError, SyntaxError):\n",
        "            return text\n",
        "    return text\n",
        "\n",
        "# פונקציה לניקוי התווים המיותרים\n",
        "def clean_text(text):\n",
        "    if isinstance(text, list):\n",
        "        text = ' '.join(text)  # הפיכת רשימה למחרוזת\n",
        "    elif isinstance(text, str):\n",
        "        # הסרת תווי רווח מיותרים ותווים מיוחדים\n",
        "        text = re.sub(r'\\n+', ' ', text)  # הסרת שורות חדשות מרובות\n",
        "        text = re.sub(r'\\\\n', '', text)   # הסרת תווי newline \\n מהטקסט\n",
        "        text = re.sub(r'\\\\xa0', ' ', text)  # הסרת תווי \\xa0 מהטקסט\n",
        "        text = re.sub(r'\\s+', ' ', text)  # הסרת רווחים מרובים\n",
        "        return text.strip()\n",
        "    return text\n",
        "\n",
        "# הדפסת שורות לא קריאות לפני המרה\n",
        "print(\"שורות לא קריאות לפני המרה:\")\n",
        "print(data[\"גוף המסמך\"].head())\n",
        "\n",
        "# המרה של הטקסטים הלא קריאים לטקסטים קריאים ושמירה על הדאטה המקורי\n",
        "data[\"גוף המסמך\"] = data[\"גוף המסמך\"].apply(clean_text)\n",
        "\n",
        "print(\"\\nשורות לאחר המרה:\")\n",
        "print(data[\"גוף המסמך\"].head())\n",
        "\n",
        "# file_path = 'full_final_df_cleaned.csv'\n",
        "# df_full_ra_rap.to_csv(file_path, index=False, encoding='utf-8')\n",
        "\n",
        "# print(f\"הקובץ נשמר בהצלחה בנתיב: {file_path}\")\n"
      ],
      "metadata": {
        "id": "TQoeCI9CXkYY"
      },
      "id": "TQoeCI9CXkYY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data[\"Outcome of case\"].unique()"
      ],
      "metadata": {
        "id": "DSE04lRQ0pMY"
      },
      "id": "DSE04lRQ0pMY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data[data[\"outcome_category\"]==2]"
      ],
      "metadata": {
        "id": "5P61Ewf9l83n"
      },
      "id": "5P61Ewf9l83n",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ygpoW9ytuT35"
      },
      "id": "ygpoW9ytuT35",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data[\"outcome_category\"].unique()"
      ],
      "metadata": {
        "id": "l949sjrGhz2g"
      },
      "id": "l949sjrGhz2g",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data[\"binary_outcome\"] = data[\"outcome_category\"].apply(lambda x: 0 if x == 0  else 1)\n",
        "\n",
        "\n",
        "#### 2 =  others -> 1\n",
        "####"
      ],
      "metadata": {
        "id": "ph2A3ykxC8bz"
      },
      "id": "ph2A3ykxC8bz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "owS1MiStvN4k"
      },
      "id": "owS1MiStvN4k"
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "id": "rEvNUN68NzRu"
      },
      "id": "rEvNUN68NzRu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "dIOnKZoNGgks",
      "metadata": {
        "id": "dIOnKZoNGgks"
      },
      "source": [
        "\n",
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"dean-ai/sentence_transformer_Legal-heBERT\")\n",
        "model = AutoModel.from_pretrained(\"dean-ai/sentence_transformer_Legal-heBERT\")"
      ],
      "metadata": {
        "id": "7dsKcvX1sNzC"
      },
      "id": "7dsKcvX1sNzC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# פונקציה שמקבלת טקסט ומחזירה את האימבדינג כוקטור\n",
        "def get_embeddings(text):\n",
        "    # המרת הטקסט לפורמט מתאים למודל\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "    # חישוב האימבדינג של המודל\n",
        "    outputs = model(**inputs)\n",
        "    # חישוב ממוצע הוקטורים עבור כל טקסט\n",
        "    embeddings = outputs.last_hidden_state.mean(dim=1).detach().numpy()\n",
        "    return embeddings[0]"
      ],
      "metadata": {
        "id": "0Nol5tbvr_1O"
      },
      "id": "0Nol5tbvr_1O",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ביטוי לבדיקה\n",
        "keyword = \"העותק כפוף לשינויי עריכה וניסוח\"\n",
        "\n",
        "# בדיקה אילו שורות מכילות את הביטוי\n",
        "rows_with_keyword = data[\"גוף המסמך\"].str.contains(keyword, na=False)\n",
        "\n",
        "# סינון שורות שלא מכילות את הביטוי\n",
        "filtered_data = data[rows_with_keyword]\n",
        "\n",
        "# הדפסת השורות שלא מכילות את הביטוי\n",
        "rows_without_keyword = data[~rows_with_keyword]\n",
        "print(\"שורות שלא מכילות את הביטוי:\\n\")\n",
        "text = (rows_without_keyword[\"גוף המסמך\"].to_string(index=False))\n",
        "formatted_text = \"\\n\".join([text[i:i+80] for i in range(0, len(text), 80)])\n",
        "print(formatted_text)\n",
        "print(\"##*******************************************************####\")\n",
        "\n",
        "# הדפסת מספר השורות שנמחקו\n",
        "num_removed = len(rows_without_keyword)\n",
        "print(f\"\\nמספר השורות שנמחקו: {num_removed}\")\n",
        "\n",
        "# שמירת הנתונים המסוננים לקובץ חדש\n",
        "filtered_data.to_csv(\"filtered_data.csv\", index=False, encoding='utf-8')\n",
        "print(\"\\nהנתונים המסוננים נשמרו לקובץ: 'filtered_data.csv'\")\n",
        "\n",
        "data = filtered_data"
      ],
      "metadata": {
        "id": "mzWC7yDCda_a"
      },
      "id": "mzWC7yDCda_a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pie_labels(data):\n",
        "  binary_counts = data['binary_outcome'].value_counts()\n",
        "  print(binary_counts)\n",
        "  labels = ['Denied (0)','Granted (1)']\n",
        "\n",
        "  plt.figure(figsize=(6, 6))\n",
        "  plt.pie(binary_counts, labels=labels, autopct='%1.1f%%', startangle=90, colors=['#66b3ff', '#ff9999'])\n",
        "  plt.title('Outcome of Case (Binary Representation)')\n",
        "\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "pie_labels(data)"
      ],
      "metadata": {
        "id": "kiIxqGBoDXwi"
      },
      "id": "kiIxqGBoDXwi",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# פונקציה לחיתוך הטקסט בהתאם לכללים\n",
        "def trim_text(text,min_length=500,last_sen=30):\n",
        "\n",
        "\n",
        "    # שמירת אורך מקורי לאבחון\n",
        "    original_length = len(text)\n",
        "\n",
        "    # הסרת מספר תווים מסוף הטקסט\n",
        "    text = text[:-last_sen]\n",
        "\n",
        "    # חיתוך ל-min_length האחרונים אם הטקסט ארוך יותר מהמינימום\n",
        "    if len(text) > min_length:\n",
        "        text = text[-min_length:]\n",
        "\n",
        "    # הדפסת פידבק רק אם הטקסט עבר שינוי\n",
        "    if len(text) != original_length:\n",
        "        print(f\"Trimmed Text (Original Length: {original_length}, Trimmed Length: {len(text)}):\")\n",
        "        formatted_text = \"\\n\".join([text[i:i+80] for i in range(0, len(text), 80)])\n",
        "        print(formatted_text)\n",
        "        print(\"##*******************************************************####\")\n",
        "    return text\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "NCFFQ8TpsDFo"
      },
      "id": "NCFFQ8TpsDFo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# הסרת שורות עם ערכים חסרים בעמודת הטקסט או בעמודת המטרה\n",
        "data = data.dropna(subset=[\"גוף המסמך\", \"outcome_category\"])\n",
        "\n",
        "#400 - 50\n",
        "\n",
        "# 500 - 30 -< 80% f1\n",
        "\n",
        "# חיתוך הטקסטים בעמודת \"גוף המסמך\"\n",
        "data[\"גוף המסמך\"] = data[\"גוף המסמך\"].apply(lambda x: trim_text(x, 550, 80))"
      ],
      "metadata": {
        "id": "BcOGhF33586E"
      },
      "id": "BcOGhF33586E",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pie_labels(data)"
      ],
      "metadata": {
        "id": "DbyCrVo6v-Ch"
      },
      "id": "DbyCrVo6v-Ch",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def train_models(data):\n",
        "#     # עדכון עמודת המטרה ואימבדינג לאחר חיתוך הטקסטים\n",
        "#     y_ = data[\"binary_outcome\"].values\n",
        "#     embeddings = np.array([get_embeddings(text) for text in data[\"גוף המסמך\"]])\n",
        "\n",
        "\n",
        "#     # הגדרת undersampler עם יחס של 60-40 לטובת קלאס 0\n",
        "#     undersampler = RandomUnderSampler(sampling_strategy=0.6, random_state=42)\n",
        "\n",
        "#     X_resampled, y_resampled = undersampler.fit_resample(embeddings, y_)\n",
        "\n",
        "#     # שמירת אינדקסים מקוריים\n",
        "#     resampled_indices = undersampler.sample_indices_\n",
        "\n",
        "#     # בדיקת תקינות האינדקסים\n",
        "#     valid_indices = [i for i in resampled_indices if i < len(data)]\n",
        "#     if len(valid_indices) < len(resampled_indices):\n",
        "#         print(f\"Warning: {len(resampled_indices) - len(valid_indices)} indices are out of bounds and will be removed.\")\n",
        "\n",
        "#     resampled_indices = valid_indices\n",
        "#     joblib.dump(resampled_indices, 'second_resampled_indices.pkl')\n",
        "\n",
        "#     # ווידוא התאמה: מיפוי y_resampled לעמודת binary_outcome\n",
        "#     binary_outcome_resampled = data.iloc[resampled_indices][\"binary_outcome\"].values\n",
        "#     if not np.array_equal(y_resampled[:len(resampled_indices)], binary_outcome_resampled):\n",
        "#         raise ValueError(\"Mismatch between y_resampled and resampled binary_outcome values!\")\n",
        "\n",
        "#     # הגדרת מסווג לוגיסטי עם משקל של 3 עבור קלאס 1\n",
        "#     classifier = LogisticRegression(random_state=42, max_iter=1000, class_weight={0: 1, 1: 3})\n",
        "\n",
        "#     # התאמת המודל לנתונים המאוזנים\n",
        "#     classifier.fit(X_resampled[:len(resampled_indices)], y_resampled[:len(resampled_indices)])\n",
        "\n",
        "#     # הגדרת מדדים לקרוס ולידציה\n",
        "#     scoring = {\n",
        "#         'accuracy': make_scorer(accuracy_score),\n",
        "#         'precision': make_scorer(precision_score, pos_label=1),\n",
        "#         'recall': make_scorer(recall_score, pos_label=1),\n",
        "#         'f1': make_scorer(f1_score, pos_label=1)\n",
        "#     }\n",
        "\n",
        "#     # ביצוע Cross Validation\n",
        "#     cv_results = cross_validate(classifier, X_resampled[:len(resampled_indices)], y_resampled[:len(resampled_indices)], cv=5, scoring=scoring)\n",
        "\n",
        "#     # חיזוי תוויות והסתברויות על כל קפל לצורך קונפיושן מטריקס והסתברויות\n",
        "#     y_pred = cross_val_predict(classifier, X_resampled[:len(resampled_indices)], y_resampled[:len(resampled_indices)], cv=5)\n",
        "#     y_prob = cross_val_predict(classifier, X_resampled[:len(resampled_indices)], y_resampled[:len(resampled_indices)], cv=5, method='predict_proba')[:, 1]  # הסתברות לקלאס 1\n",
        "#     conf_matrix = confusion_matrix(y_resampled[:len(resampled_indices)], y_pred)\n",
        "\n",
        "#     # הדפסת התוצאות\n",
        "#     print(\"Cross-Validation Accuracy:\", cv_results['test_accuracy'])\n",
        "#     print(\"Mean Accuracy:\", cv_results['test_accuracy'].mean())\n",
        "#     print(\"Cross-Validation Precision for Class 1:\", cv_results['test_precision'])\n",
        "#     print(\"Mean Precision for Class 1:\", cv_results['test_precision'].mean())\n",
        "#     print(\"Cross-Validation Recall for Class 1:\", cv_results['test_recall'])\n",
        "#     print(\"Mean Recall for Class 1:\", cv_results['test_recall'].mean())\n",
        "#     print(\"Cross-Validation F1 Score for Class 1:\", cv_results['test_f1'])\n",
        "#     print(\"Mean F1 Score for Class 1:\", cv_results['test_f1'].mean())\n",
        "\n",
        "#     tn, fp, fn, tp = conf_matrix.ravel()\n",
        "\n",
        "#     # הדפסת הקונפיושן מטריקס עם תוויות\n",
        "#     print(\"Confusion Matrix with Labels:\")\n",
        "#     print(f\"True Negatives (TN): {tn}\")\n",
        "#     print(f\"False Positives (FP): {fp}\")\n",
        "#     print(f\"False Negatives (FN): {fn}\")\n",
        "#     print(f\"True Positives (TP): {tp}\")\n",
        "\n",
        "#     print(\"\\nConfusion Matrix:\")\n",
        "#     print(f\"[[{tn} {fp}]\")\n",
        "#     print(f\" [{fn} {tp}]]\")\n",
        "\n",
        "#     # שמירת האינדקסים המקוריים של הדגימות המסומפלות\n",
        "#     original_indices = data.index[resampled_indices]\n",
        "\n",
        "#     # הוספת עמודת הסתברויות\n",
        "#     data['predicted_probabilities'] = np.nan\n",
        "#     data.loc[original_indices, 'predicted_probabilities'] = y_prob\n",
        "\n",
        "#     # שמירת המודל והמשאבים\n",
        "#     joblib.dump(classifier, 'second_classifier_model.pkl')\n",
        "#     data.to_csv('updated_data_with_probabilities_2.csv', index=False)\n",
        "\n",
        "#     print(\"המודל, התוצאות והנתונים נשמרו בהצלחה.\")\n",
        "\n",
        "#     return data,embeddings,classifier,X_resampled,y_resampled, resampled_indices\n"
      ],
      "metadata": {
        "id": "Es2KMSZ8vllO"
      },
      "id": "Es2KMSZ8vllO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_models(data):\n",
        "    # עדכון עמודת המטרה ואימבדינג לאחר חיתוך הטקסטים\n",
        "    y_ = data[\"binary_outcome\"].values\n",
        "    embeddings = np.array([get_embeddings(text) for text in data[\"גוף המסמך\"]])\n",
        "\n",
        "    # הגדרת undersampler עם יחס של 60-40 לטובת קלאס 0\n",
        "    undersampler = RandomUnderSampler(sampling_strategy=0.8, random_state=42)\n",
        "    X_resampled, y_resampled = undersampler.fit_resample(embeddings, y_)\n",
        "\n",
        "    # שמירת אינדקסים מקוריים\n",
        "    resampled_indices = undersampler.sample_indices_\n",
        "\n",
        "    # בדיקת תקינות האינדקסים\n",
        "    valid_indices = [i for i in resampled_indices if i < len(data)]\n",
        "    if len(valid_indices) < len(resampled_indices):\n",
        "        print(f\"Warning: {len(resampled_indices) - len(valid_indices)} indices are out of bounds and will be removed.\")\n",
        "    resampled_indices = valid_indices\n",
        "    joblib.dump(resampled_indices, 'second_resampled_indices.pkl')\n",
        "\n",
        "    # ווידוא התאמה: מיפוי y_resampled לעמודת binary_outcome\n",
        "    binary_outcome_resampled = data.iloc[resampled_indices][\"binary_outcome\"].values\n",
        "    if not np.array_equal(y_resampled[:len(resampled_indices)], binary_outcome_resampled):\n",
        "        raise ValueError(\"Mismatch between y_resampled and resampled binary_outcome values!\")\n",
        "\n",
        "    # הגדרת מסווג לוגיסטי עם משקל של 3 עבור קלאס 1\n",
        "    classifier = LogisticRegression(random_state=42, max_iter=1000, class_weight={0: 1, 1: 3})\n",
        "\n",
        "    # התאמת המודל לנתונים המאוזנים\n",
        "    classifier.fit(X_resampled[:len(resampled_indices)], y_resampled[:len(resampled_indices)])\n",
        "\n",
        "    # הגדרת מדדים לקרוס ולידציה\n",
        "    scoring = {\n",
        "        'accuracy': make_scorer(accuracy_score),\n",
        "        'precision': make_scorer(precision_score, pos_label=1),\n",
        "        'recall': make_scorer(recall_score, pos_label=1),\n",
        "        'f1': make_scorer(f1_score, pos_label=1)\n",
        "    }\n",
        "\n",
        "    # ביצוע Cross Validation\n",
        "    cv_results = cross_validate(\n",
        "        classifier,\n",
        "        X_resampled[:len(resampled_indices)],\n",
        "        y_resampled[:len(resampled_indices)],\n",
        "        cv=5,\n",
        "        scoring=scoring\n",
        "    )\n",
        "\n",
        "    # חיזוי תוויות והסתברויות על כל קפל (Cross Val Predict)\n",
        "    y_pred = cross_val_predict(\n",
        "        classifier,\n",
        "        X_resampled[:len(resampled_indices)],\n",
        "        y_resampled[:len(resampled_indices)],\n",
        "        cv=5\n",
        "    )\n",
        "    y_prob = cross_val_predict(\n",
        "        classifier,\n",
        "        X_resampled[:len(resampled_indices)],\n",
        "        y_resampled[:len(resampled_indices)],\n",
        "        cv=5,\n",
        "        method='predict_proba'\n",
        "    )[:, 1]  # הסתברות לקלאס 1\n",
        "\n",
        "    conf_matrix = confusion_matrix(\n",
        "        y_resampled[:len(resampled_indices)],\n",
        "        y_pred\n",
        "    )\n",
        "\n",
        "    # הדפסת התוצאות\n",
        "    print(\"Cross-Validation Accuracy:\", cv_results['test_accuracy'])\n",
        "    print(\"Mean Accuracy:\", cv_results['test_accuracy'].mean())\n",
        "    print(\"Cross-Validation Precision for Class 1:\", cv_results['test_precision'])\n",
        "    print(\"Mean Precision for Class 1:\", cv_results['test_precision'].mean())\n",
        "    print(\"Cross-Validation Recall for Class 1:\", cv_results['test_recall'])\n",
        "    print(\"Mean Recall for Class 1:\", cv_results['test_recall'].mean())\n",
        "    print(\"Cross-Validation F1 Score for Class 1:\", cv_results['test_f1'])\n",
        "    print(\"Mean F1 Score for Class 1:\", cv_results['test_f1'].mean())\n",
        "\n",
        "    tn, fp, fn, tp = conf_matrix.ravel()\n",
        "\n",
        "    # הדפסת הקונפיושן מטריקס עם תוויות\n",
        "    print(\"Confusion Matrix with Labels:\")\n",
        "    print(f\"True Negatives (TN): {tn}\")\n",
        "    print(f\"False Positives (FP): {fp}\")\n",
        "    print(f\"False Negatives (FN): {fn}\")\n",
        "    print(f\"True Positives (TP): {tp}\")\n",
        "\n",
        "    print(\"\\nConfusion Matrix:\")\n",
        "    print(f\"[[{tn} {fp}]\")\n",
        "    print(f\" [{fn} {tp}]]\")\n",
        "\n",
        "    # שמירת האינדקסים המקוריים של הדגימות המסומפלות\n",
        "    original_indices = data.index[resampled_indices]\n",
        "\n",
        "    # ------------------ הוספת עמודת 'predicted_probabilities' ------------------ #\n",
        "    data['predicted_probabilities'] = np.nan\n",
        "    data.loc[original_indices, 'predicted_probabilities'] = y_prob\n",
        "\n",
        "    # ------------------ הוספת עמודת 'error_type' (TP, FP, TN, FN) ------------------ #\n",
        "    # ניצור רשימה של סוג השגיאה/הניבוי עבור כל רשומה ברשמפלינג\n",
        "    error_types = []\n",
        "    errors = []\n",
        "    for true_label, predicted_label in zip(y_resampled[:len(resampled_indices)], y_pred):\n",
        "        if true_label == 1 and predicted_label == 1:\n",
        "            error_types.append(\"TP\")\n",
        "            errors.append(0)\n",
        "        elif true_label == 0 and predicted_label == 0:\n",
        "            error_types.append(\"TN\")\n",
        "            errors.append(0)\n",
        "        elif true_label == 0 and predicted_label == 1:\n",
        "            error_types.append(\"FP\")\n",
        "            errors.append(1)\n",
        "        elif true_label == 1 and predicted_label == 0:\n",
        "            error_types.append(\"FN\")\n",
        "            errors.append(1)\n",
        "        else:\n",
        "            error_types.append(\"UNKNOWN\")  # למקרה שמשהו לא צפוי\n",
        "\n",
        "    # יוצרים עמודה ריקה בנתונים המקוריים\n",
        "    data['error_type'] = np.nan\n",
        "    data['errors'] = np.nan\n",
        "    # מחדירים את הערכים רק לאינדקסים שרשמפלנו\n",
        "    data.loc[original_indices, 'error_type'] = error_types\n",
        "    data.loc[original_indices, 'errors'] = errors\n",
        "\n",
        "    # שמירת המודל והמשאבים\n",
        "    joblib.dump(classifier, 'second_classifier_model.pkl')\n",
        "    data.to_csv('SECOND_CLASSIFIER_updated_data_with_probabilities_2.csv', index=False)\n",
        "    data.to_excel('SECOND_CLASSIFIER_updated_data_with_probabilities_2.xlsx', index=False)\n",
        "\n",
        "    print(\"המודל, התוצאות והנתונים נשמרו בהצלחה.\")\n",
        "\n",
        "    return data, embeddings, classifier, X_resampled, y_resampled, resampled_indices\n"
      ],
      "metadata": {
        "id": "r5SvUJHef-sq"
      },
      "id": "r5SvUJHef-sq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data,embeddings, classifier, X_resampled,y_resampled, resampled_indices = train_models(data)"
      ],
      "metadata": {
        "id": "QaHI8Y3JVcgi"
      },
      "id": "QaHI8Y3JVcgi",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "id": "4w8EtO9dgC0F"
      },
      "id": "4w8EtO9dgC0F",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data[data['error_type']==\"UNKNOWN\"].value_counts()"
      ],
      "metadata": {
        "id": "wWmdzHOPgoM5"
      },
      "id": "wWmdzHOPgoM5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.to_excel('SECOND_CLASSIFIER_updated_data_with_probabilities_2.xlsx', index=False)"
      ],
      "metadata": {
        "id": "xnojzBQextU-"
      },
      "id": "xnojzBQextU-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_FN(data, classifier, X_resampled, y_resampled, resampled_indices):\n",
        "    # חיזוי תוויות על כל קפל לצורך זיהוי FN\n",
        "    y_pred = cross_val_predict(classifier, X_resampled, y_resampled, cv=5)\n",
        "\n",
        "    # חיזוי הסתברויות\n",
        "    y_prob = cross_val_predict(classifier, X_resampled, y_resampled, cv=5, method='predict_proba')[:, 1]\n",
        "\n",
        "    # איתור האינדקסים של FN - תווית אמיתית היא 1 והתחזית היא 0\n",
        "    fn_indices = np.where((y_resampled == 1) & (y_pred == 0))[0]\n",
        "\n",
        "    # ודא ש-resampled_indices הוא numpy array\n",
        "    resampled_indices = np.array(resampled_indices)\n",
        "\n",
        "    # מיפוי האינדקסים של FN לאינדקסים המקוריים של הנתונים\n",
        "    original_fn_indices = resampled_indices[fn_indices]\n",
        "\n",
        "    # קריאת פסקי הדין והערכים בעמודות \"Outcome of case\", \"binary_outcome\", \"Predicted\" ו-\"Probability\" עבור הדוגמאות שמזוהות כ-FN\n",
        "    false_negative_rows = data.iloc[original_fn_indices]\n",
        "    false_negative_probabilities = y_prob[fn_indices]  # ההסתברויות של המודל עבור FN\n",
        "    false_negative_predicted = y_pred[fn_indices]  # התחזיות של המודל עבור FN\n",
        "\n",
        "    # ווידוא סינכרון מוחלט של האינדקסים\n",
        "    if len(false_negative_rows) != len(false_negative_predicted):\n",
        "        raise ValueError(\"Mismatch between FN rows and predicted labels!\")\n",
        "\n",
        "    # הדפסת פסקי הדין של FN בצורה מפורמטת עם הערכים המקוריים, התחזית, וההסתברות\n",
        "    print(\"False Negative Cases (True Label: 1, Predicted Label: 0):\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    for i, (index, row, predicted, probability) in enumerate(zip(original_fn_indices, false_negative_rows.iterrows(), false_negative_predicted, false_negative_probabilities), 1):\n",
        "        _, row_data = row\n",
        "        print(f\"\\nCase {i}:\")\n",
        "        print(\"-\" * 80)\n",
        "        print(\"Index in Original Data:\")\n",
        "        print(index)\n",
        "        print(\"\\nOriginal Outcome of Case:\")\n",
        "        print(row_data[\"Outcome of case\"])\n",
        "        print(\"\\nBinary Outcome (True Label):\")\n",
        "        print(row_data[\"binary_outcome\"])\n",
        "        print(\"\\nPredicted Label:\")\n",
        "        print(predicted)\n",
        "        print(\"\\nPredicted Probability:\")\n",
        "        print(f\"{probability:.4f}\")\n",
        "        print(\"\\nDocument Body:\")\n",
        "        formatted_text = \"\\n\".join(row_data[\"גוף המסמך\"][j:j + 80] for j in range(0, len(row_data[\"גוף המסמך\"]), 80))\n",
        "        print(formatted_text)\n",
        "        print(\"-\" * 80)\n",
        "\n",
        "    print(\"=\" * 80)\n"
      ],
      "metadata": {
        "id": "U3q6DOEAEAWG"
      },
      "id": "U3q6DOEAEAWG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_FN(data,classifier,X_resampled,y_resampled, resampled_indices)"
      ],
      "metadata": {
        "id": "_ijxP4KMZlGO"
      },
      "id": "_ijxP4KMZlGO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "i4B8X3b_6TEo"
      },
      "id": "i4B8X3b_6TEo",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}