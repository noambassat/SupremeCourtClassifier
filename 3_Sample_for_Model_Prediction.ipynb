{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/noambassat/SupremeCourtClassifier/blob/main/3_Sample_for_Model_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "id": "7ed8bbc1-7bb6-4c95-b239-068b265fbdf4",
      "metadata": {
        "id": "7ed8bbc1-7bb6-4c95-b239-068b265fbdf4"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from pandas.api.types import CategoricalDtype\n",
        "import ast"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f64e26b-5b69-4f98-bec2-7da5787c9feb",
      "metadata": {
        "id": "7f64e26b-5b69-4f98-bec2-7da5787c9feb"
      },
      "outputs": [],
      "source": [
        "df_full_ra_rap = pd.read_excel(\"full_ra_rap.xlsx\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JAWsV-l-_6xs"
      },
      "id": "JAWsV-l-_6xs",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b570f17-74f4-4337-a54e-9fc41495d107",
      "metadata": {
        "id": "5b570f17-74f4-4337-a54e-9fc41495d107"
      },
      "outputs": [],
      "source": [
        "df_full_ra_rap"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d711b2af-fcff-4722-bf4d-fe1bd319effb",
      "metadata": {
        "id": "d711b2af-fcff-4722-bf4d-fe1bd319effb"
      },
      "source": [
        "# Clean Doc's body - נקיון גוף המסמך"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "335441c2-f389-4d9c-a3ad-5cf2b589375b",
      "metadata": {
        "id": "335441c2-f389-4d9c-a3ad-5cf2b589375b"
      },
      "outputs": [],
      "source": [
        "print((df_full_ra_rap[\"גוף המסמך\"].iloc[2]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f24c14d0-34e6-48c4-b340-a0fee540ff1c",
      "metadata": {
        "id": "f24c14d0-34e6-48c4-b340-a0fee540ff1c"
      },
      "outputs": [],
      "source": [
        "# פונקציה להמרת טקסט שמופיע כרשימה למחרוזת רגילה\n",
        "def convert_list_to_string(text):\n",
        "    if isinstance(text, str) and text.startswith(\"[\") and text.endswith(\"]\"):\n",
        "        try:\n",
        "            # מנסה להמיר את התוכן בתוך הסוגריים לרשימה אמיתית\n",
        "            text_list = ast.literal_eval(text)\n",
        "            # איחוד המחרוזות לרצף טקסט אחד\n",
        "            return ' '.join(text_list)\n",
        "        except (ValueError, SyntaxError):\n",
        "            return text\n",
        "    return text\n",
        "\n",
        "# פונקציה לניקוי התווים המיותרים\n",
        "def clean_text(text):\n",
        "    if isinstance(text, list):\n",
        "        text = ' '.join(text)  # הפיכת רשימה למחרוזת\n",
        "    elif isinstance(text, str):\n",
        "        # הסרת תווי רווח מיותרים ותווים מיוחדים\n",
        "        text = re.sub(r'\\n+', ' ', text)  # הסרת שורות חדשות מרובות\n",
        "        text = re.sub(r'\\\\n', '', text)   # הסרת תווי newline \\n מהטקסט\n",
        "        text = re.sub(r'\\\\xa0', ' ', text)  # הסרת תווי \\xa0 מהטקסט\n",
        "        text = re.sub(r'\\s+', ' ', text)  # הסרת רווחים מרובים\n",
        "        return text.strip()\n",
        "    return text\n",
        "\n",
        "# הדפסת שורות לא קריאות לפני המרה\n",
        "print(\"שורות לא קריאות לפני המרה:\")\n",
        "print(df_full_ra_rap[\"גוף המסמך\"].head())\n",
        "\n",
        "# המרה של הטקסטים הלא קריאים לטקסטים קריאים ושמירה על הדאטה המקורי\n",
        "df_full_ra_rap[\"גוף המסמך\"] = df_full_ra_rap[\"גוף המסמך\"].apply(clean_text)\n",
        "\n",
        "print(\"\\nשורות לאחר המרה:\")\n",
        "print(df_full_ra_rap[\"גוף המסמך\"].head())\n",
        "\n",
        "# file_path = 'full_final_df_cleaned.csv'\n",
        "# df_full_ra_rap.to_csv(file_path, index=False, encoding='utf-8')\n",
        "\n",
        "# print(f\"הקובץ נשמר בהצלחה בנתיב: {file_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9d78afc0-8502-47df-b77c-2227f6f22734",
      "metadata": {
        "id": "9d78afc0-8502-47df-b77c-2227f6f22734"
      },
      "source": [
        "# DCA Files only"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6dc673bf-4b16-4153-a295-0329f79ba47a",
      "metadata": {
        "id": "6dc673bf-4b16-4153-a295-0329f79ba47a"
      },
      "outputs": [],
      "source": [
        "df_full_rap = df_full_ra_rap[df_full_ra_rap[\"סוג הליך\"]=='רע\"פ']\n",
        "df_full_rap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hxU6RD3lHhvy",
      "metadata": {
        "id": "hxU6RD3lHhvy"
      },
      "outputs": [],
      "source": [
        "years =[2020,2015,2010,2005,2000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "zeciFpN5DOzW",
      "metadata": {
        "id": "zeciFpN5DOzW"
      },
      "outputs": [],
      "source": [
        "sample_df = df_full_ra_rap[df_full_ra_rap[\"שנת פתיחת ההליך\"].isin(years)]\n",
        "sample_df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "GnF7KztHI9lE",
      "metadata": {
        "id": "GnF7KztHI9lE"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "340a9e45-cb60-420a-9658-474cc96f7a31",
      "metadata": {
        "id": "340a9e45-cb60-420a-9658-474cc96f7a31"
      },
      "outputs": [],
      "source": [
        "sample_df.shape[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c7cc26ae-367c-4b78-a431-7a0f8c718ba3",
      "metadata": {
        "id": "c7cc26ae-367c-4b78-a431-7a0f8c718ba3"
      },
      "source": [
        "# Drop null"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bdedf7ed-a774-4064-a2e9-a5ca41e95b24",
      "metadata": {
        "id": "bdedf7ed-a774-4064-a2e9-a5ca41e95b24"
      },
      "outputs": [],
      "source": [
        "sample_df[[\"גוף המסמך\"]].dropna(how='any', ignore_index=True,inplace=True)\n",
        "sample_df[[\"מספר הליך\",\"שם הליך\"]].dropna(how='all', ignore_index=True,inplace=True)\n",
        "sample_df[[\"מספר הליך\",\"שם הליך\"]].drop_duplicates(inplace=True, ignore_index=True)\n",
        "sample_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dAJCuOvcJ5_S",
      "metadata": {
        "id": "dAJCuOvcJ5_S"
      },
      "outputs": [],
      "source": [
        "cut_sample_df = sample_df[[\"גוף המסמך\",\"מספר הליך\",\"שם הליך\",\"שנת פתיחת ההליך\"]].reset_index()\n",
        "cut_sample_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "20KqX9kqYyMQ",
      "metadata": {
        "id": "20KqX9kqYyMQ"
      },
      "outputs": [],
      "source": [
        "cut_sample_df.to_csv(\"cut_sample_df.csv\", index=False, encoding='utf-8')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "DfpCrQ0eYy5c",
      "metadata": {
        "id": "DfpCrQ0eYy5c"
      },
      "source": [
        "# Cut missing ending files"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## FIX THIS!!!\n"
      ],
      "metadata": {
        "id": "DWWOc2Yvqr1N"
      },
      "id": "DWWOc2Yvqr1N"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "GHSHDYlLZMA4",
      "metadata": {
        "id": "GHSHDYlLZMA4"
      },
      "outputs": [],
      "source": [
        "# הגדרת פונקציה לעיצוב טקסט\n",
        "def format_text(text, line_length=80):\n",
        "    \"\"\"\n",
        "    פורמט טקסט כך שיהיה נוח לקריאה עם שורות שאורכן מוגבל.\n",
        "    \"\"\"\n",
        "    import textwrap\n",
        "    return \"\\n\".join(textwrap.wrap(text, width=line_length))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "mPmkMXnCMENR",
      "metadata": {
        "id": "mPmkMXnCMENR"
      },
      "outputs": [],
      "source": [
        "# # ביטויים לבדיקה\n",
        "# keywords = [\"העותק כפוף לשינויי עריכה וניסוח\", \"העתק מתאים\", 'ניתנההיום', 'ניתןהיום', 'ניתן היום', 'ניתנה היום',\n",
        "#             \"העתקמתאים\", \"מזכיר ראשי\", \"supreme.court.gov.il\", \"מרכז מידע\", \"מרכזמידע\"]\n",
        "\n",
        "# # בדיקה אילו שורות מכילות אחד מהביטויים\n",
        "# rows_with_keyword = cut_sample_df[\"גוף המסמך\"].apply(\n",
        "#     lambda x: any(keyword in x for keyword in keywords) if isinstance(x, str) else False\n",
        "# )\n",
        "\n",
        "# # סינון שורות שלא מכילות את הביטוי\n",
        "# filtered_data = cut_sample_df[rows_with_keyword]\n",
        "\n",
        "# # הדפסת מספר השורות שנמחקו\n",
        "# num_removed = len(cut_sample_df) - len(filtered_data)  # **שונה לחישוב מדויק**\n",
        "# print(f\"\\nמספר השורות שנמחקו: {num_removed}\")\n",
        "\n",
        "# # **שינוי לצורך סעיף 6**: בדיקה אם נותרו ערכים חסרים בעמודת \"גוף המסמך\"\n",
        "# missing_values_count = filtered_data[\"גוף המסמך\"].isna().sum()\n",
        "# if missing_values_count > 0:\n",
        "#     print(f\"\\nנותרו {missing_values_count} ערכים חסרים בעמודת 'גוף המסמך' לאחר סינון.\")\n",
        "# else:\n",
        "#     print(\"\\nאין ערכים חסרים בעמודת 'גוף המסמך' לאחר סינון.\")\n",
        "\n",
        "# # שמירת הנתונים המסוננים לקובץ חדש\n",
        "# filtered_data.to_csv(\"new_filtered_data.csv\", index=False, encoding='utf-8')\n",
        "# print(\"\\nהנתונים המסוננים נשמרו לקובץ: 'new_filtered_data.csv'\")\n",
        "\n",
        "# # עדכון הטבלה המקורית\n",
        "# cut_sample_df = filtered_data.copy()  # **שונה להעתקה בטוחה**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Jj461YqoXbTq",
      "metadata": {
        "id": "Jj461YqoXbTq"
      },
      "outputs": [],
      "source": [
        "# פונקציה לחיתוך הטקסט בהתאם לכללים\n",
        "def trim_text(text):\n",
        "    min_length = 500  # אורך מינימלי לשמירה\n",
        "    last_sen = 30     # מספר תווים להסרה מסוף הטקסט\n",
        "\n",
        "    # שמירת אורך מקורי לאבחון\n",
        "    original_length = len(text)\n",
        "\n",
        "    # הסרת מספר תווים מסוף הטקסט\n",
        "    text = text[:-last_sen]\n",
        "\n",
        "    # חיתוך ל-min_length האחרונים אם הטקסט ארוך יותר מהמינימום\n",
        "    if len(text) > min_length:\n",
        "        text = text[-min_length:]\n",
        "\n",
        "    return text\n",
        "\n",
        "# הסרת שורות עם ערכים חסרים בעמודת \"גוף המסמך\"\n",
        "cut_sample_df = cut_sample_df.dropna(subset=[\"גוף המסמך\"]).copy()\n",
        "\n",
        "# חיתוך הטקסטים בעמודת \"גוף המסמך\"\n",
        "cut_sample_df[\"גוף המסמך חתוך\"] = cut_sample_df[\"גוף המסמך\"].apply(trim_text)\n",
        "\n",
        "# שמירת האינדקס המקורי\n",
        "cut_sample_df.reset_index(inplace=True, drop=False)  # שונה להבטחת שמירת אינדקס מקורי\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "vIYlVqraX3iN",
      "metadata": {
        "id": "vIYlVqraX3iN"
      },
      "outputs": [],
      "source": [
        "cut_sample_df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Embedding"
      ],
      "metadata": {
        "id": "rdfILDSmiPl8"
      },
      "id": "rdfILDSmiPl8"
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModel\n",
        "import numpy as np\n",
        "import joblib\n",
        "import pandas as pd\n",
        "\n",
        "# טעינת המודל והטוקנייזר\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"dean-ai/sentence_transformer_Legal-heBERT\")\n",
        "model = AutoModel.from_pretrained(\"dean-ai/sentence_transformer_Legal-heBERT\")\n",
        "\n",
        "# פונקציה שמקבלת טקסט ומחזירה את האימבדינג כוקטור\n",
        "def get_embeddings(text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "    outputs = model(**inputs)\n",
        "    embeddings = outputs.last_hidden_state.mean(dim=1).detach().numpy()\n",
        "    return embeddings[0]\n",
        "\n",
        "# בדיקה אם עמודת \"גוף המסמך חתוך\" קיימת ומכילה ערכים תקינים\n",
        "if \"גוף המסמך חתוך\" not in cut_sample_df.columns or cut_sample_df[\"גוף המסמך חתוך\"].isna().all():\n",
        "    raise ValueError(\"עמודת 'גוף המסמך חתוך' חסרה או ריקה. יש לוודא חיתוך טקסטים תקין לפני המשך.\")\n",
        "\n",
        "# חישוב האימבדינגים עבור כל שורה בעמודת \"גוף המסמך חתוך\"\n",
        "print(\"מתחילים לחשב אימבדינגים על גוף המסמך החתוך...\")\n",
        "embeddings_new = np.array([get_embeddings(text) for text in cut_sample_df[\"גוף המסמך חתוך\"]])\n",
        "print(\"אימבדינגים חושבו בהצלחה!\")\n"
      ],
      "metadata": {
        "id": "FTaxCIxzLnb1"
      },
      "id": "FTaxCIxzLnb1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Model prediction"
      ],
      "metadata": {
        "id": "VAkyRLJCic4T"
      },
      "id": "VAkyRLJCic4T"
    },
    {
      "cell_type": "code",
      "source": [
        "# טוען את המודל\n",
        "classifier = joblib.load(\"classifier_model.pkl\")\n",
        "\n",
        "print(\"המודל נטען בהצלחה.\")\n",
        "\n",
        "# חיזוי הסתברויות\n",
        "print(\"מתחילים לחזות הסתברויות...\")\n",
        "predicted_probabilities = classifier.predict_proba(embeddings_new)[:, 1]\n",
        "print(\"הסתברויות נחזו בהצלחה!\")\n",
        "\n",
        "# הוספת עמודת ההסתברויות\n",
        "cut_sample_df[\"predicted_probability\"] = predicted_probabilities\n",
        "\n",
        "# יצירת תחזיות לפי המודל המקורי (ללא שימוש בטרשהולד מותאם)\n",
        "cut_sample_df[\"prediction_original_model\"] = classifier.predict(embeddings_new)\n",
        "\n",
        "# **תוספת סעיף 4**: בדיקת התפלגות התחזיות\n",
        "class_distribution = cut_sample_df[\"prediction_original_model\"].value_counts()\n",
        "print(\"\\nכמות Class 0 ו-Class 1 (לפי המודל המקורי):\")\n",
        "print(class_distribution)\n",
        "\n",
        "# בדיקת התפלגות נורמלית\n",
        "normalized_distribution = cut_sample_df[\"prediction_original_model\"].value_counts(normalize=True)\n",
        "print(\"\\nהתפלגות נורמלית של Class 0 ו-Class 1 (לפי המודל המקורי):\")\n",
        "print(normalized_distribution)\n",
        "\n",
        "# שמירה של התחזיות והנתונים לקובץ Excel\n",
        "output_file = \"full_data_with_predictions.xlsx\"\n",
        "cut_sample_df.to_excel(output_file, index=False, engine=\"openpyxl\")\n",
        "print(f\"הטבלה המלאה עם הפרדיקציות נשמרה בקובץ: '{output_file}'\")\n"
      ],
      "metadata": {
        "id": "VvjHV8j_zYE7"
      },
      "id": "VvjHV8j_zYE7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cut_sample_df"
      ],
      "metadata": {
        "id": "wtkxmGAzr6X-"
      },
      "id": "wtkxmGAzr6X-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Analysis"
      ],
      "metadata": {
        "id": "J9D4JB1iwD3Z"
      },
      "id": "J9D4JB1iwD3Z"
    },
    {
      "cell_type": "code",
      "source": [
        "# ווידוא שקיימת עמודת שנה\n",
        "if \"שנת פתיחת ההליך\" not in cut_sample_df.columns:\n",
        "    raise ValueError(\"עמודת 'שנה' חסרה בדאטה. יש לוודא שהמידע קיים לפני המשך.\")\n",
        "\n",
        "# יצירת טבלת התפלגות\n",
        "class_distribution_by_year = cut_sample_df.groupby(\"שנת פתיחת ההליך\")[\"prediction_original_model\"].value_counts(normalize=True).unstack(fill_value=0)\n",
        "\n",
        "# המרה לאחוזים\n",
        "class_distribution_by_year = class_distribution_by_year * 100\n",
        "\n",
        "# הדפסת התפלגות הכיתות לפי שנה\n",
        "print(\"התפלגות הכיתות לפי תחזיות המודל (%):\")\n",
        "print(class_distribution_by_year)\n",
        "\n",
        "# שמירה לקובץ Excel\n",
        "output_file = \"class_distribution_by_year.xlsx\"\n",
        "class_distribution_by_year.to_excel(output_file, engine=\"openpyxl\")\n",
        "# print(f\"התפלגות הכיתות נשמרה בקובץ: {output_file}\")\n"
      ],
      "metadata": {
        "id": "pOrcyvgJDsXP"
      },
      "id": "pOrcyvgJDsXP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_1 = pd.read_csv(\"dca_for_classifier.csv\")"
      ],
      "metadata": {
        "id": "e8PnuXgixc5W"
      },
      "id": "e8PnuXgixc5W",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# בדיקת אורכים מקוריים\n",
        "original_lengths_train = data_1[\"גוף המסמך\"].str.len()\n",
        "original_lengths_predict = cut_sample_df[\"גוף המסמך\"].str.len()\n",
        "\n",
        "print(f\"אורך ממוצע של הטקסטים המקוריים באימון: {original_lengths_train.mean():.2f}\")\n",
        "print(f\"אורך ממוצע של הטקסטים המקוריים בחיזוי: {original_lengths_predict.mean():.2f}\")\n",
        "\n",
        "# בדיקת אורכים לאחר חיתוך\n",
        "trimmed_lengths_train = data_1[\"גוף המסמך\"].apply(trim_text).str.len()\n",
        "trimmed_lengths_predict = cut_sample_df[\"גוף המסמך\"].apply(trim_text).str.len()\n",
        "\n",
        "print(f\"אורך ממוצע של הטקסטים החתוכים באימון: {trimmed_lengths_train.mean():.2f}\")\n",
        "print(f\"אורך ממוצע של הטקסטים החתוכים בחיזוי: {trimmed_lengths_predict.mean():.2f}\")\n"
      ],
      "metadata": {
        "id": "qtB1ajupxNzf"
      },
      "id": "qtB1ajupxNzf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cut_sample_df.columns"
      ],
      "metadata": {
        "id": "CVieyYiJvieA"
      },
      "id": "CVieyYiJvieA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# סעיף 3: השוואת נתוני האימון לחיזוי\n",
        "print(\"\\n--- השוואת נתוני האימון לנתוני החיזוי ---\")\n",
        "\n",
        "# קריאת נתוני האימון (מתוך קובץ האימון)\n",
        "train_data = pd.read_csv(\"dca_for_classifier.csv\")  # עדכני לנתוני האימון שלך\n",
        "\n",
        "# השוואת אורכי הטקסטים\n",
        "train_text_lengths = train_data[\"גוף המסמך\"].str.len()\n",
        "test_text_lengths = cut_sample_df[\"גוף המסמך\"].str.len()\n",
        "\n",
        "print(f\"אורך ממוצע של טקסטים באימון: {train_text_lengths.mean():.2f}\")\n",
        "print(f\"אורך ממוצע של טקסטים בחיזוי: {test_text_lengths.mean():.2f}\")\n",
        "\n",
        "# השוואת אחוז מילות המפתח\n",
        "keywords = [\"העותק כפוף לשינויי עריכה וניסוח\", \"העתק מתאים\", \"ניתנה היום\", \"מרכז מידע\"]\n",
        "train_keyword_percentage = train_data[\"גוף המסמך\"].apply(lambda x: any(kw in x for kw in keywords)).mean()\n",
        "test_keyword_percentage = cut_sample_df[\"גוף המסמך\"].apply(lambda x: any(kw in x for kw in keywords)).mean()\n",
        "\n",
        "print(f\"אחוז טקסטים עם מילות מפתח באימון: {train_keyword_percentage * 100:.2f}%\")\n",
        "print(f\"אחוז טקסטים עם מילות מפתח בחיזוי: {test_keyword_percentage * 100:.2f}%\")\n",
        "\n",
        "# השוואת שיעור Class 1 באימון ובחיזוי\n",
        "train_class_1_ratio = train_data[\"binary_outcome\"].mean()\n",
        "predicted_class_1_ratio = cut_sample_df[\"prediction_original_model\"].mean()\n",
        "\n",
        "print(f\"שיעור Class 1 באימון: {train_class_1_ratio * 100:.2f}%\")\n",
        "print(f\"שיעור Class 1 בחיזוי: {predicted_class_1_ratio * 100:.2f}%\")\n"
      ],
      "metadata": {
        "id": "xJ8eqCUDvcwp"
      },
      "id": "xJ8eqCUDvcwp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# סעיף 4: ווידוא המשקלים של המודל\n",
        "print(\"\\n--- ווידוא משקלי המודל ---\")\n",
        "\n",
        "# בדיקת משקל הכיתות במודל\n",
        "if hasattr(classifier, \"class_weight\"):\n",
        "    print(f\"משקלי הכיתות במודל: {classifier.class_weight}\")\n",
        "else:\n",
        "    print(\"לא הוגדרו משקלי כיתות במודל.\")\n",
        "\n",
        "# חישוב שיעור Class 0 ו-Class 1 בחיזוי\n",
        "predicted_class_distribution = cut_sample_df[\"prediction_original_model\"].value_counts(normalize=True)\n",
        "print(\"\\nהתפלגות תחזיות המודל:\")\n",
        "print(predicted_class_distribution)\n",
        "\n",
        "# ווידוא שאכן יש רוב ל-Class 0\n",
        "if predicted_class_distribution.get(0, 0) <= 0.5:\n",
        "    print(\"אזהרה: רוב התחזיות אינן עבור Class 0. ייתכן שהמודל לא מאוזן כהלכה.\")\n"
      ],
      "metadata": {
        "id": "RUt21veHvuEo"
      },
      "id": "RUt21veHvuEo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ווידוא שקיימת עמודת שנה\n",
        "if \"שנת פתיחת ההליך\" not in cut_sample_df.columns:\n",
        "    raise ValueError(\"עמודת 'שנת פתיחת ההליך' חסרה בדאטה. יש לוודא שהמידע קיים לפני המשך.\")\n",
        "\n",
        "# יצירת קבוצות לפי שנת פתיחת ההליך\n",
        "grouped_by_year = cut_sample_df.groupby(\"שנת פתיחת ההליך\")\n",
        "\n",
        "# הדפסת מדגם של 5 מקרים לכל שנה שסווגו כ-Class 1\n",
        "print(\"Cases Predicted as Class 1 (Sample of up to 5 cases per year):\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "for year, group in grouped_by_year:\n",
        "    # סינון המקרים שסווגו כ-Class 1 עבור השנה\n",
        "    class_1_rows = group[group[\"prediction_original_model\"] == 1]\n",
        "\n",
        "    # בחירת מדגם של עד 5 מקרים\n",
        "    sampled_class_1_rows = class_1_rows.sample(n=min(5, len(class_1_rows)), random_state=42)\n",
        "\n",
        "    # הדפסת מקרים עבור השנה\n",
        "    print(f\"\\nYear: {year}\")\n",
        "    print(\"-\" * 80)\n",
        "\n",
        "    for i, (index, row) in enumerate(sampled_class_1_rows.iterrows(), 1):\n",
        "        print(f\"\\nCase {i}:\")\n",
        "        print(\"-\" * 80)\n",
        "        print(\"Index in Original Data:\")\n",
        "        print(index)\n",
        "        print(\"\\nPredicted Probability for Class 1:\")\n",
        "        print(row[\"predicted_probability\"])\n",
        "        print(\"\\nPredicted Label:\")\n",
        "        print(row[\"prediction_original_model\"])\n",
        "        print(\"\\nDocument Body:\")\n",
        "        formatted_text = \"\\n\".join(row[\"גוף המסמך\"][j:j + 80] for j in range(0, len(row[\"גוף המסמך\"]), 80))\n",
        "        print(formatted_text)\n",
        "        print(\"-\" * 80)\n",
        "\n",
        "    print(\"=\" * 80)\n"
      ],
      "metadata": {
        "id": "cN3M_7f6H1dQ"
      },
      "id": "cN3M_7f6H1dQ",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}