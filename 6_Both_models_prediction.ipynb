{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/noambassat/SupremeCourtClassifier/blob/main/6_Both_models_prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "7ed8bbc1-7bb6-4c95-b239-068b265fbdf4",
      "metadata": {
        "id": "7ed8bbc1-7bb6-4c95-b239-068b265fbdf4"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from pandas.api.types import CategoricalDtype\n",
        "import ast\n",
        "import joblib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f64e26b-5b69-4f98-bec2-7da5787c9feb",
      "metadata": {
        "id": "7f64e26b-5b69-4f98-bec2-7da5787c9feb"
      },
      "outputs": [],
      "source": [
        "raap = pd.read_csv(\"RAAP.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for col in raap.columns:\n",
        "  print(col)"
      ],
      "metadata": {
        "id": "JAWsV-l-_6xs"
      },
      "id": "JAWsV-l-_6xs",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raap[\"ניתנה החלטה כמבוקש הבקשה\"].unique()"
      ],
      "metadata": {
        "id": "PJ5WugBk0g6I"
      },
      "id": "PJ5WugBk0g6I",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "נקודה חשובה לציון - בשנים 2000-2001 יש הבדל מהותי בין שם ההליך ומתוכו סוג ההליך, לבין סוג ההליך שנרשם בגוף המסמך עצמו."
      ],
      "metadata": {
        "id": "v-qqP0l3bRIR"
      },
      "id": "v-qqP0l3bRIR"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b570f17-74f4-4337-a54e-9fc41495d107",
      "metadata": {
        "id": "5b570f17-74f4-4337-a54e-9fc41495d107"
      },
      "outputs": [],
      "source": [
        "raap"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d711b2af-fcff-4722-bf4d-fe1bd319effb",
      "metadata": {
        "id": "d711b2af-fcff-4722-bf4d-fe1bd319effb"
      },
      "source": [
        "# Clean Doc's body - נקיון גוף המסמך"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "335441c2-f389-4d9c-a3ad-5cf2b589375b",
      "metadata": {
        "id": "335441c2-f389-4d9c-a3ad-5cf2b589375b"
      },
      "outputs": [],
      "source": [
        "print((raap[\"גוף המסמך\"].iloc[2]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f24c14d0-34e6-48c4-b340-a0fee540ff1c",
      "metadata": {
        "id": "f24c14d0-34e6-48c4-b340-a0fee540ff1c"
      },
      "outputs": [],
      "source": [
        "# פונקציה להמרת טקסט שמופיע כרשימה למחרוזת רגילה\n",
        "def convert_list_to_string(text):\n",
        "    if isinstance(text, str) and text.startswith(\"[\") and text.endswith(\"]\"):\n",
        "        try:\n",
        "            # מנסה להמיר את התוכן בתוך הסוגריים לרשימה אמיתית\n",
        "            text_list = ast.literal_eval(text)\n",
        "            # איחוד המחרוזות לרצף טקסט אחד\n",
        "            return ' '.join(text_list)\n",
        "        except (ValueError, SyntaxError):\n",
        "            return text\n",
        "    return text\n",
        "\n",
        "# פונקציה לניקוי התווים המיותרים\n",
        "def clean_text(text):\n",
        "    if isinstance(text, list):\n",
        "        text = ' '.join(text)  # הפיכת רשימה למחרוזת\n",
        "    elif isinstance(text, str):\n",
        "        # הסרת תווי רווח מיותרים ותווים מיוחדים\n",
        "        text = re.sub(r'\\n+', ' ', text)  # הסרת שורות חדשות מרובות\n",
        "        text = re.sub(r'\\\\n', '', text)   # הסרת תווי newline \\n מהטקסט\n",
        "        text = re.sub(r'\\\\xa0', ' ', text)  # הסרת תווי \\xa0 מהטקסט\n",
        "        text = re.sub(r'\\s+', ' ', text)  # הסרת רווחים מרובים\n",
        "        return text.strip()\n",
        "    return text\n",
        "\n",
        "# הדפסת שורות לא קריאות לפני המרה\n",
        "print(\"שורות לא קריאות לפני המרה:\")\n",
        "print(raap[\"גוף המסמך\"].head())\n",
        "\n",
        "# המרה של הטקסטים הלא קריאים לטקסטים קריאים ושמירה על הדאטה המקורי\n",
        "raap[\"גוף המסמך\"] = raap[\"גוף המסמך\"].apply(clean_text)\n",
        "\n",
        "print(\"\\nשורות לאחר המרה:\")\n",
        "print(raap[\"גוף המסמך\"].head())\n",
        "\n",
        "# file_path = 'full_final_df_cleaned.csv'\n",
        "# df_full_ra_rap.to_csv(file_path, index=False, encoding='utf-8')\n",
        "\n",
        "# print(f\"הקובץ נשמר בהצלחה בנתיב: {file_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9d78afc0-8502-47df-b77c-2227f6f22734",
      "metadata": {
        "id": "9d78afc0-8502-47df-b77c-2227f6f22734"
      },
      "source": [
        "# DCA Files only"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hxU6RD3lHhvy",
      "metadata": {
        "id": "hxU6RD3lHhvy"
      },
      "outputs": [],
      "source": [
        "years = list(range(2008, 2015, 1))\n",
        "years"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "zeciFpN5DOzW",
      "metadata": {
        "id": "zeciFpN5DOzW"
      },
      "outputs": [],
      "source": [
        "sample_df = raap[raap[\"שנת פתיחת ההליך\"].isin(years)]\n",
        "sample_df"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_df[\"שנת פתיחת ההליך\"].unique()"
      ],
      "metadata": {
        "id": "4CvSID1OOnz1"
      },
      "id": "4CvSID1OOnz1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FO9DrhyeOq1x"
      },
      "id": "FO9DrhyeOq1x",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "GmCGnbGeeEOd"
      },
      "id": "GmCGnbGeeEOd"
    },
    {
      "cell_type": "code",
      "source": [
        "sample_df = sample_df[sample_df[\"סוג הליך\"]=='רע\"פ']\n",
        "# בדיקה אם בעמודת \"גוף המסמך\" קיימת המילה \"רע\"פ\"\n",
        "contains_raap = sample_df[\"גוף המסמך\"].str.contains('רע\"פ', na=False)\n",
        "\n",
        "# ספירה של כמה מסמכים מכילים את המילה רע\"פ וכמה לא\n",
        "count_yes = contains_raap.sum()\n",
        "count_no = len(contains_raap) - count_yes\n",
        "\n",
        "# הדפסת הספירה\n",
        "print(f\"מספר המסמכים שמכילים את המילה 'רע\\\"פ': {count_yes}\")\n",
        "print(f\"מספר המסמכים שלא מכילים את המילה 'רע\\\"פ': {count_no}\")\n",
        "\n",
        "# סינון הדאטה לשמירת רק המסמכים שכן מכילות את המילה\n",
        "sample_df = sample_df[contains_raap]\n",
        "\n",
        "# שמירה לקובץ חדש אם יש צורך\n",
        "output_file = \"filtered_sample_with_raap.csv\"\n",
        "sample_df.to_csv(output_file, index=False, encoding=\"utf-8\")\n",
        "print(f\"הדאטה המסונן נשמר לקובץ: '{output_file}'\")\n"
      ],
      "metadata": {
        "id": "Rc9glkwFNmda"
      },
      "id": "Rc9glkwFNmda",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_df = sample_df[\n",
        "    (sample_df[\"סוג הליך\"] == 'רע\"פ') &\n",
        "    (sample_df[\"מספר הליך\"].str.contains('רע\"פ', na=False))\n",
        "]\n",
        "sample_df"
      ],
      "metadata": {
        "id": "Va5TVOzyOw6z"
      },
      "id": "Va5TVOzyOw6z",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "GnF7KztHI9lE",
      "metadata": {
        "id": "GnF7KztHI9lE"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "340a9e45-cb60-420a-9658-474cc96f7a31",
      "metadata": {
        "id": "340a9e45-cb60-420a-9658-474cc96f7a31"
      },
      "outputs": [],
      "source": [
        "sample_df.shape[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c7cc26ae-367c-4b78-a431-7a0f8c718ba3",
      "metadata": {
        "id": "c7cc26ae-367c-4b78-a431-7a0f8c718ba3"
      },
      "source": [
        "# Drop null"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bdedf7ed-a774-4064-a2e9-a5ca41e95b24",
      "metadata": {
        "id": "bdedf7ed-a774-4064-a2e9-a5ca41e95b24"
      },
      "outputs": [],
      "source": [
        "sample_df[[\"גוף המסמך\"]].dropna(how='any', ignore_index=True,inplace=True)\n",
        "sample_df[[\"מספר הליך\",\"שם הליך\"]].dropna(how='all', ignore_index=True,inplace=True)\n",
        "sample_df[[\"מספר הליך\",\"שם הליך\"]].drop_duplicates(inplace=True, ignore_index=True)\n",
        "sample_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dAJCuOvcJ5_S",
      "metadata": {
        "id": "dAJCuOvcJ5_S"
      },
      "outputs": [],
      "source": [
        "cut_sample_df = sample_df[[\"גוף המסמך\",\"מספר הליך\",\"שם הליך\",\"שנת פתיחת ההליך\"]].reset_index()\n",
        "cut_sample_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "20KqX9kqYyMQ",
      "metadata": {
        "id": "20KqX9kqYyMQ"
      },
      "outputs": [],
      "source": [
        "cut_sample_df.to_csv(\"cut_sample_df.csv\", index=False, encoding='utf-8')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "DfpCrQ0eYy5c",
      "metadata": {
        "id": "DfpCrQ0eYy5c"
      },
      "source": [
        "# Cut missing ending files"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## FIX THIS!!!\n"
      ],
      "metadata": {
        "id": "DWWOc2Yvqr1N"
      },
      "id": "DWWOc2Yvqr1N"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "GHSHDYlLZMA4",
      "metadata": {
        "id": "GHSHDYlLZMA4"
      },
      "outputs": [],
      "source": [
        "# הגדרת פונקציה לעיצוב טקסט\n",
        "def format_text(text, line_length=80):\n",
        "    \"\"\"\n",
        "    פורמט טקסט כך שיהיה נוח לקריאה עם שורות שאורכן מוגבל.\n",
        "    \"\"\"\n",
        "    import textwrap\n",
        "    return \"\\n\".join(textwrap.wrap(text, width=line_length))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "mPmkMXnCMENR",
      "metadata": {
        "id": "mPmkMXnCMENR"
      },
      "outputs": [],
      "source": [
        "# ביטויים לבדיקה\n",
        "keywords = [\"העותק כפוף לשינויי עריכה וניסוח\", \"העתק מתאים\", 'ניתנההיום', 'ניתןהיום', 'ניתן היום', 'ניתנה היום',\n",
        "            \"העתקמתאים\", \"מזכיר ראשי\", \"supreme.court.gov.il\", \"מרכז מידע\", \"מרכזמידע\"]\n",
        "\n",
        "# בדיקה אילו שורות מכילות אחד מהביטויים\n",
        "rows_with_keyword = cut_sample_df[\"גוף המסמך\"].apply(\n",
        "    lambda x: any(keyword in x for keyword in keywords) if isinstance(x, str) else False\n",
        ")\n",
        "\n",
        "# סינון שורות שלא מכילות את הביטוי\n",
        "filtered_data = cut_sample_df[rows_with_keyword]\n",
        "\n",
        "# הדפסת מספר השורות שנמחקו\n",
        "num_removed = len(cut_sample_df) - len(filtered_data)  # **שונה לחישוב מדויק**\n",
        "print(f\"\\nמספר השורות שנמחקו: {num_removed}\")\n",
        "\n",
        "# **שינוי לצורך סעיף 6**: בדיקה אם נותרו ערכים חסרים בעמודת \"גוף המסמך\"\n",
        "missing_values_count = filtered_data[\"גוף המסמך\"].isna().sum()\n",
        "if missing_values_count > 0:\n",
        "    print(f\"\\nנותרו {missing_values_count} ערכים חסרים בעמודת 'גוף המסמך' לאחר סינון.\")\n",
        "else:\n",
        "    print(\"\\nאין ערכים חסרים בעמודת 'גוף המסמך' לאחר סינון.\")\n",
        "\n",
        "\n",
        "# עדכון הטבלה המקורית\n",
        "cut_sample_df = filtered_data.copy()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ביטוי לבדיקה\n",
        "keyword = \"העותק כפוף לשינויי עריכה וניסוח\"\n",
        "\n",
        "# בדיקה אילו שורות מכילות את הביטוי\n",
        "rows_with_keyword = cut_sample_df[\"גוף המסמך\"].str.contains(keyword, na=False)\n",
        "\n",
        "# סינון שורות שלא מכילות את הביטוי\n",
        "filtered_data = cut_sample_df[rows_with_keyword]\n",
        "\n",
        "# הדפסת השורות שלא מכילות את הביטוי\n",
        "rows_without_keyword = cut_sample_df[~rows_with_keyword]\n",
        "print(\"שורות שלא מכילות את הביטוי:\\n\")\n",
        "text = (rows_without_keyword[\"גוף המסמך\"].to_string(index=False))\n",
        "formatted_text = \"\\n\".join([text[i:i+80] for i in range(0, len(text), 80)])\n",
        "print(formatted_text)\n",
        "print(\"##*******************************************************####\")\n",
        "\n",
        "# הדפסת מספר השורות שנמחקו\n",
        "num_removed = len(rows_without_keyword)\n",
        "print(f\"\\nמספר השורות שנמחקו: {num_removed}\")\n",
        "\n",
        "# שמירת הנתונים המסוננים לקובץ חדש\n",
        "filtered_data.to_csv(\"filtered_data.csv\", index=False, encoding='utf-8')\n",
        "print(\"\\nהנתונים המסוננים נשמרו לקובץ: 'filtered_data.csv'\")\n",
        "\n",
        "cut_sample_df = filtered_data"
      ],
      "metadata": {
        "id": "3elQ_1R3VpnS"
      },
      "id": "3elQ_1R3VpnS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Jj461YqoXbTq",
      "metadata": {
        "id": "Jj461YqoXbTq"
      },
      "outputs": [],
      "source": [
        "# פונקציה לחיתוך הטקסט בהתאם לכללים\n",
        "def trim_text(text,min_length=500,last_sen=30):\n",
        "\n",
        "\n",
        "    # שמירת אורך מקורי לאבחון\n",
        "    original_length = len(text)\n",
        "\n",
        "    # הסרת מספר תווים מסוף הטקסט\n",
        "    text = text[:-last_sen]\n",
        "\n",
        "    # חיתוך ל-min_length האחרונים אם הטקסט ארוך יותר מהמינימום\n",
        "    if len(text) > min_length:\n",
        "        text = text[-min_length:]\n",
        "\n",
        "    # הדפסת פידבק רק אם הטקסט עבר שינוי\n",
        "    if len(text) != original_length:\n",
        "        print(f\"Trimmed Text (Original Length: {original_length}, Trimmed Length: {len(text)}):\")\n",
        "        formatted_text = \"\\n\".join([text[i:i+80] for i in range(0, len(text), 80)])\n",
        "        print(formatted_text)\n",
        "        print(\"##*******************************************************####\")\n",
        "    return text\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# הסרת שורות עם ערכים חסרים בעמודת \"גוף המסמך\"\n",
        "cut_sample_df = cut_sample_df.dropna(subset=[\"גוף המסמך\"]).copy()\n",
        "\n",
        "# חיתוך הטקסטים בעמודת \"גוף המסמך\"\n",
        "cut_sample_df[\"גוף המסמך חתוך\"] = cut_sample_df[\"גוף המסמך\"].apply(trim_text)\n",
        "\n",
        "# שמירת האינדקס המקורי\n",
        "cut_sample_df.reset_index(inplace=True, drop=False)  # שונה להבטחת שמירת אינדקס מקורי\n"
      ],
      "metadata": {
        "id": "dbo49aedWDdJ"
      },
      "id": "dbo49aedWDdJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "vIYlVqraX3iN",
      "metadata": {
        "id": "vIYlVqraX3iN"
      },
      "outputs": [],
      "source": [
        "cut_sample_df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Embedding"
      ],
      "metadata": {
        "id": "rdfILDSmiPl8"
      },
      "id": "rdfILDSmiPl8"
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModel\n",
        "import numpy as np\n",
        "import joblib\n",
        "import pandas as pd\n",
        "\n",
        "# טעינת המודל והטוקנייזר\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"dean-ai/sentence_transformer_Legal-heBERT\")\n",
        "model = AutoModel.from_pretrained(\"dean-ai/sentence_transformer_Legal-heBERT\")\n",
        "\n",
        "# פונקציה שמקבלת טקסט ומחזירה את האימבדינג כוקטור\n",
        "def get_embeddings(text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "    outputs = model(**inputs)\n",
        "    embeddings = outputs.last_hidden_state.mean(dim=1).detach().numpy()\n",
        "    return embeddings[0]\n",
        "\n",
        "# בדיקה אם עמודת \"גוף המסמך חתוך\" קיימת ומכילה ערכים תקינים\n",
        "if \"גוף המסמך חתוך\" not in cut_sample_df.columns or cut_sample_df[\"גוף המסמך חתוך\"].isna().all():\n",
        "    raise ValueError(\"עמודת 'גוף המסמך חתוך' חסרה או ריקה. יש לוודא חיתוך טקסטים תקין לפני המשך.\")\n",
        "\n",
        "# חישוב האימבדינגים עבור כל שורה בעמודת \"גוף המסמך חתוך\"\n",
        "print(\"מתחילים לחשב אימבדינגים על גוף המסמך החתוך...\")\n",
        "embeddings_new = np.array([get_embeddings(text) for text in cut_sample_df[\"גוף המסמך חתוך\"]])\n",
        "print(\"אימבדינגים חושבו בהצלחה!\")\n"
      ],
      "metadata": {
        "id": "FTaxCIxzLnb1"
      },
      "id": "FTaxCIxzLnb1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Model prediction"
      ],
      "metadata": {
        "id": "VAkyRLJCic4T"
      },
      "id": "VAkyRLJCic4T"
    },
    {
      "cell_type": "code",
      "source": [
        "# טוען את המודל\n",
        "classifier = joblib.load(\"2_classifier_model_double_trained.pkl\")\n",
        "print(\"המודל נטען בהצלחה.\")\n",
        "\n",
        "# חיזוי הסתברויות\n",
        "print(\"מתחילים לחזות הסתברויות...\")\n",
        "predicted_probabilities = classifier.predict_proba(embeddings_new)[:, 1]\n",
        "print(\"הסתברויות נחזו בהצלחה!\")\n",
        "\n",
        "# הוספת עמודת ההסתברויות\n",
        "cut_sample_df[\"predicted_probability\"] = predicted_probabilities\n",
        "\n",
        "\n",
        "\n",
        "# יצירת תחזיות לפי המודל המקורי (ללא שימוש בטרשהולד מותאם)\n",
        "cut_sample_df[\"prediction_original_model\"] = classifier.predict(embeddings_new)\n",
        "\n",
        "# **תוספת סעיף 4**: בדיקת התפלגות התחזיות\n",
        "class_distribution = cut_sample_df[\"prediction_original_model\"].value_counts()\n",
        "print(\"\\nכמות Class 0 ו-Class 1 (לפי המודל המקורי):\")\n",
        "print(class_distribution)\n",
        "\n",
        "# בדיקת התפלגות נורמלית\n",
        "normalized_distribution = cut_sample_df[\"prediction_original_model\"].value_counts(normalize=True)\n",
        "print(\"\\nהתפלגות נורמלית של Class 0 ו-Class 1 (לפי המודל המקורי):\")\n",
        "print(normalized_distribution)\n",
        "\n",
        "\n",
        "# שמירה של התחזיות והנתונים לקובץ Excel\n",
        "output_file = \"2_full_data_with_predictions.xlsx\"\n",
        "cut_sample_df.to_excel(output_file, index=False, engine=\"openpyxl\")\n",
        "print(f\"הטבלה המלאה עם הפרדיקציות נשמרה בקובץ: '{output_file}'\")\n"
      ],
      "metadata": {
        "id": "rA6P5TU0L3mO"
      },
      "id": "rA6P5TU0L3mO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Analysis"
      ],
      "metadata": {
        "id": "J9D4JB1iwD3Z"
      },
      "id": "J9D4JB1iwD3Z"
    },
    {
      "cell_type": "code",
      "source": [
        "# ווידוא שקיימת עמודת שנה\n",
        "if \"שנת פתיחת ההליך\" not in cut_sample_df.columns:\n",
        "    raise ValueError(\"עמודת 'שנת פתיחת ההליך' חסרה בדאטה. יש לוודא שהמידע קיים לפני המשך.\")\n",
        "\n",
        "# בדיקת כמות הערכים לכל שנה\n",
        "year_counts = cut_sample_df[\"שנת פתיחת ההליך\"].value_counts().sort_index()\n",
        "print(\"\\nNumber of values for each year:\")\n",
        "print(year_counts)\n",
        "\n",
        "# יצירת טבלת התפלגות\n",
        "class_distribution_by_year = cut_sample_df.groupby(\"שנת פתיחת ההליך\")[\"prediction_original_model\"].value_counts(normalize=True).unstack(fill_value=0)\n",
        "\n",
        "# המרה לאחוזים\n",
        "class_distribution_by_year = class_distribution_by_year * 100\n",
        "\n",
        "# הדפסת התפלגות הכיתות לפי שנה\n",
        "print(\"\\nהתפלגות הכיתות לפי תחזיות המודל (%):\")\n",
        "print(class_distribution_by_year)\n",
        "\n",
        "# שמירה לקובץ Excel\n",
        "output_file = \"3_no_treshold_class_distribution_by_year.xlsx\"\n",
        "class_distribution_by_year.to_excel(output_file, engine=\"openpyxl\")\n",
        "print(f\"\\nהתפלגות הכיתות נשמרה בקובץ: {output_file}\")\n"
      ],
      "metadata": {
        "id": "YvH7rEl3-L_y"
      },
      "id": "YvH7rEl3-L_y",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import rcParams\n",
        "\n",
        "# הגדרת פונט\n",
        "rcParams['font.family'] = 'DejaVu Sans'  # מתאים כברירת מחדל\n",
        "\n",
        "def plot_probability_distribution_separate_by_year(df, year_column, probability_column, bins=50):\n",
        "    \"\"\"\n",
        "    Displays a separate histogram for each year of the probability distribution.\n",
        "\n",
        "    Parameters:\n",
        "    df: pandas.DataFrame - The data table.\n",
        "    year_column: str - The column name representing the year.\n",
        "    probability_column: str - The column name representing the probabilities.\n",
        "    bins: int - The number of bins in the histogram.\n",
        "    \"\"\"\n",
        "    # Check if the columns exist\n",
        "    if year_column not in df.columns or probability_column not in df.columns:\n",
        "        raise ValueError(f\"Columns {year_column} or {probability_column} are missing in the DataFrame.\")\n",
        "\n",
        "    # Get unique years\n",
        "    unique_years = sorted(df[year_column].dropna().unique())\n",
        "\n",
        "    # Create separate histograms for each year\n",
        "    for year in unique_years:\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        plt.hist(\n",
        "            df[df[year_column] == year][probability_column],\n",
        "            bins=bins,\n",
        "            alpha=0.7,\n",
        "            color=\"blue\",\n",
        "            edgecolor=\"black\"\n",
        "        )\n",
        "\n",
        "        # Set graph labels and titles\n",
        "        plt.title(f\"Probability Distribution for Year {year}\", fontsize=16, loc='center')\n",
        "        plt.xlabel(\"Predicted Probability\", fontsize=14)\n",
        "        plt.ylabel(\"Frequency\", fontsize=14)\n",
        "        plt.xlim(0, 1)  # Probabilities always between 0 and 1\n",
        "        plt.grid(True, linestyle='--', alpha=0.6)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n"
      ],
      "metadata": {
        "id": "q88qrFOun2zY"
      },
      "id": "q88qrFOun2zY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ווידוא שעומדת \"שנת פתיחת ההליך\" קיימת\n",
        "if \"שנת פתיחת ההליך\" not in cut_sample_df.columns:\n",
        "    raise ValueError(\"עמודת 'שנת פתיחת ההליך' חסרה ב-DataFrame.\")\n",
        "\n",
        "# קריאה לפונקציה להצגת גרף נפרד לכל שנה\n",
        "plot_probability_distribution_separate_by_year(cut_sample_df, \"שנת פתיחת ההליך\", \"predicted_probability\")\n"
      ],
      "metadata": {
        "id": "BmkUFE-uoAdC"
      },
      "id": "BmkUFE-uoAdC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Second classifier prediction  "
      ],
      "metadata": {
        "id": "yRXOJV9iMl8O"
      },
      "id": "yRXOJV9iMl8O"
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_excel(\"2_full_data_with_predictions.xlsx\")"
      ],
      "metadata": {
        "id": "8a4rAZQzMsMe"
      },
      "id": "8a4rAZQzMsMe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[df[\"prediction_original_model\"]==1].shape[0]"
      ],
      "metadata": {
        "id": "R61qM6_-M-Qd"
      },
      "id": "R61qM6_-M-Qd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[df[\"prediction_original_model\"]==1]"
      ],
      "metadata": {
        "id": "3OVnoaPDNIJm"
      },
      "id": "3OVnoaPDNIJm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = df[df[\"prediction_original_model\"]==1]"
      ],
      "metadata": {
        "id": "QEn86ocpNFs2"
      },
      "id": "QEn86ocpNFs2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "FrUvmTTG80yI"
      },
      "id": "FrUvmTTG80yI"
    },
    {
      "cell_type": "code",
      "source": [
        "# פונקציה שמקבלת טקסט ומחזירה את האימבדינג כוקטור\n",
        "def get_embeddings(text):\n",
        "    # המרת הטקסט לפורמט מתאים למודל\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "    # חישוב האימבדינג של המודל\n",
        "    outputs = model(**inputs)\n",
        "    # חישוב ממוצע הוקטורים עבור כל טקסט\n",
        "    embeddings = outputs.last_hidden_state.mean(dim=1).detach().numpy()\n",
        "    return embeddings[0]"
      ],
      "metadata": {
        "id": "bj1gzbqJN8qR"
      },
      "id": "bj1gzbqJN8qR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data[\"גוף המסמך חתוך מסווג שני\"] = data[\"גוף המסמך\"].apply(lambda x: trim_text(x, 550, 80))"
      ],
      "metadata": {
        "id": "qP2drvEJOA_j"
      },
      "id": "qP2drvEJOA_j",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xIcm_az4WMcf"
      },
      "id": "xIcm_az4WMcf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings_new = np.array([get_embeddings(text) for text in data[\"גוף המסמך חתוך מסווג שני\"]])"
      ],
      "metadata": {
        "id": "hRiWghqGPKY2"
      },
      "id": "hRiWghqGPKY2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# טוען את המודל\n",
        "second_classifier = joblib.load(\"second_classifier_model.pkl\")\n",
        "print(\"המודל נטען בהצלחה.\")\n",
        "\n",
        "# חיזוי הסתברויות\n",
        "print(\"מתחילים לחזות הסתברויות...\")\n",
        "predicted_probabilities = classifier.predict_proba(embeddings_new)[:, 1]\n",
        "print(\"הסתברויות נחזו בהצלחה!\")\n",
        "\n",
        "# הוספת עמודת ההסתברויות\n",
        "data[\"second_model_predicted_probability\"] = predicted_probabilities\n",
        "\n",
        "\n",
        "\n",
        "# יצירת תחזיות לפי המודל המקורי (ללא שימוש בטרשהולד מותאם)\n",
        "data[\"prediction_second_model\"] = classifier.predict(embeddings_new)\n",
        "\n",
        "# **תוספת סעיף 4**: בדיקת התפלגות התחזיות\n",
        "class_distribution = data[\"prediction_second_model\"].value_counts()\n",
        "print(\"\\nכמות Class 0 ו-Class 1 (לפי המודל המקורי):\")\n",
        "print(class_distribution)\n",
        "\n",
        "# בדיקת התפלגות נורמלית\n",
        "normalized_distribution = data[\"prediction_second_model\"].value_counts(normalize=True)\n",
        "print(\"\\nהתפלגות נורמלית של Class 0 ו-Class 1 (לפי המודל המקורי):\")\n",
        "print(normalized_distribution)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "NYZXds6RRox2"
      },
      "id": "NYZXds6RRox2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SMaMka5O97jy"
      },
      "id": "SMaMka5O97jy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.concat([data,df])"
      ],
      "metadata": {
        "id": "1LBFCWLfRucF"
      },
      "id": "1LBFCWLfRucF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.drop_duplicates(subset = [\"מספר הליך\"],keep = 'first', inplace=True)"
      ],
      "metadata": {
        "id": "Kj0pe1GgWhSt"
      },
      "id": "Kj0pe1GgWhSt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# שמירה של התחזיות והנתונים לקובץ Excel\n",
        "output_file = \"full_data_both_models_with_predictions.xlsx\"\n",
        "data.to_excel(output_file, index=False, engine=\"openpyxl\")\n",
        "print(f\"הטבלה המלאה עם הפרדיקציות נשמרה בקובץ: '{output_file}'\")\n"
      ],
      "metadata": {
        "id": "2sJVeWW-WgQE"
      },
      "id": "2sJVeWW-WgQE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data[data[\"prediction_second_model\"]==0]"
      ],
      "metadata": {
        "id": "-v5j80D7W2FX"
      },
      "id": "-v5j80D7W2FX",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}