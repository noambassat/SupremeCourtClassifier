{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "cell_execution_strategy": "setup",
      "authorship_tag": "ABX9TyPfdxDLezglde3oASBmDLDQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/noambassat/SupremeCourtClassifier/blob/main/LLM_Court.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "vvVtg-CzCG2y"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import joblib\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive\n",
        "import time\n",
        "import re\n",
        "import openai\n",
        "import json\n",
        "from sklearn.model_selection import train_test_split\n",
        "import ast"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def fix_hebrew_labels(ax):\n",
        "    \"\"\" Reverse Hebrew labels in Matplotlib plots. \"\"\"\n",
        "    for label in ax.get_xticklabels() + ax.get_yticklabels():\n",
        "        text = label.get_text()\n",
        "        if any(\"\\u0590\" <= char <= \"\\u05FF\" for char in text):  # Detect Hebrew characters\n",
        "            label.set_text(text[::-1])\n",
        "    ax.figure.canvas.draw()\n"
      ],
      "metadata": {
        "id": "V-qebznTV7Sm"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rUu4l0zkFPox",
        "outputId": "9fbbea9f-57ef-479a-b0a5-f387db532a22"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "folder_id = \"×‘×™×ª ×”××©×¤×˜ - ×§×‘×¦×™× ×©× ×‘×“×§×•\"\n",
        "directory_path = f\"/content/drive/My Drive/{folder_id}\"\n",
        "classifiers_path = \"/content/drive/MyDrive/×‘×™×ª ×”××©×¤×˜ - ××¡×•×•×’×™×/\"\n",
        "\n",
        "if not os.path.exists(directory_path):\n",
        "    print(f\"Directory {directory_path} does not exist. Please check the folder path.\")\n",
        "else:\n",
        "    dataframes = []\n",
        "\n",
        "    for file_name in os.listdir(directory_path):\n",
        "        if file_name.endswith(\".xlsx\") or file_name.endswith(\".xls\"):\n",
        "            file_path = os.path.join(directory_path, file_name)\n",
        "            try:\n",
        "                df = pd.read_excel(file_path)\n",
        "                dataframes.append(df)\n",
        "            except Exception as e:\n",
        "                print(f\"Failed to read {file_name}: {e}\")\n",
        "\n",
        "    if dataframes:\n",
        "        combined_df = pd.concat(dataframes, ignore_index=True)\n",
        "        print(\"All Excel files have been concatenated successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7-8rCVEjDjXf",
        "outputId": "e2895f01-30cb-461d-82d6-4623e74f638d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Data Validation extension is not supported and will be removed\n",
            "  warn(msg)\n",
            "/usr/local/lib/python3.11/dist-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Data Validation extension is not supported and will be removed\n",
            "  warn(msg)\n",
            "/usr/local/lib/python3.11/dist-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Data Validation extension is not supported and will be removed\n",
            "  warn(msg)\n",
            "/usr/local/lib/python3.11/dist-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Data Validation extension is not supported and will be removed\n",
            "  warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All Excel files have been concatenated successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "full_ra_rap = pd.read_excel(\"/content/drive/My Drive/full_ra_rap.xlsx\")"
      ],
      "metadata": {
        "id": "ysV94PcW_8Ol"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "check_gender_bias = pd.concat([dataframes[0], dataframes[1], dataframes[2]])\n",
        "check_gender_bias = pd.merge(full_ra_rap, check_gender_bias, on='××¡×¤×¨ ×”×œ×™×š', how='left')\n",
        "check_gender_bias.drop_duplicates(subset = '××¡×¤×¨ ×”×œ×™×š',inplace = True)\n",
        "check_gender_bias.dropna(subset = [\"×‘×§×©×” ×œ×¨×©×•×ª ×¢×¨×¢×•×¨ ×”×ª×§×‘×œ×”?\"],inplace=True)"
      ],
      "metadata": {
        "id": "ZsdLraC9_0iM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for col in check_gender_bias.columns:\n",
        "    if(col.find(\"××’×“×¨\")!=-1 or col.find(\"×¢×¨×¢×•×¨\")!=-1 or col.find(\"××¡×¤×¨ \")!=-1):\n",
        "      print(col)"
      ],
      "metadata": {
        "id": "FljLeZkhB5yE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "check_gender_bias = check_gender_bias[[\"××¡×¤×¨ ×”×œ×™×š\",\"××¡×¤×¨ ×”×©×•×¤×˜×™×\",\"×‘×§×©×” ×œ×¨×©×•×ª ×¢×¨×¢×•×¨ ×”×ª×§×‘×œ×”?\",\"××’×“×¨\"]]"
      ],
      "metadata": {
        "id": "h8EkRHnENJTS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "check_gender_bias[[\"×‘×§×©×” ×œ×¨×©×•×ª ×¢×¨×¢×•×¨ ×”×ª×§×‘×œ×”?\",\"××’×“×¨\"]]"
      ],
      "metadata": {
        "id": "tczUJbPLCHcA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from ast import literal_eval\n",
        "\n",
        "\n",
        "# ×”××¨×ª ×”××—×¨×•×–×ª ×‘×¨×©×™××ª ××’×“×¨×™× ×œ××‘× ×” ×¨×©×™××”\n",
        "check_gender_bias[\"××’×“×¨\"] = check_gender_bias[\"××’×“×¨\"].apply(literal_eval)  # ×××™×¨ ×˜×§×¡×˜ ×œ×¨×©×™××”\n",
        "\n",
        "# ×¤×•× ×§×¦×™×” ×œ×”×©×˜×—×ª ×”× ×ª×•× ×™× â€“ ×›×œ ×©×•×¤×˜ ×™×§×‘×œ ×©×•×¨×” ××©×œ×•\n",
        "def expand_genders(df):\n",
        "    expanded_data = []\n",
        "    for _, row in df.iterrows():\n",
        "        for gender in row[\"××’×“×¨\"]:\n",
        "            expanded_data.append({\"Gender\": gender, \"Appeal Outcome\": row[\"×‘×§×©×” ×œ×¨×©×•×ª ×¢×¨×¢×•×¨ ×”×ª×§×‘×œ×”?\"]})\n",
        "    return pd.DataFrame(expanded_data)\n",
        "\n",
        "# ×”×¨×—×‘×ª ×”×˜×‘×œ×”\n",
        "df_expanded = expand_genders(check_gender_bias)\n",
        "\n",
        "# ×¡×¤×™×¨×ª ×ª×•×¦××•×ª ×”×¢×¨×¢×•×¨ ×œ×¤×™ ××’×“×¨\n",
        "outcome_counts = df_expanded.groupby([\"Gender\", \"Appeal Outcome\"]).size().unstack().fillna(0)\n",
        "\n",
        "# ×™×¦×™×¨×ª ×’×¨×£ ×”×ª×¤×œ×’×•×ª ×ª×•×¦××•×ª ×œ×¤×™ ××’×“×¨\n",
        "plt.figure(figsize=(8, 5))\n",
        "outcome_counts.plot(kind=\"bar\", stacked=True)\n",
        "plt.ylabel(\"××¡×¤×¨ ×¢×¨×¢×•×¨×™×\")\n",
        "plt.title(\"×”×ª×¤×œ×’×•×ª ×ª×•×¦××•×ª ×”×¢×¨×¢×•×¨ ×œ×¤×™ ××’×“×¨ ×”×©×•×¤×˜/×ª\")\n",
        "plt.xticks(rotation=0)\n",
        "plt.legend(title=\"×ª×•×¦××ª ×”×¢×¨×¢×•×¨\")\n",
        "plt.show()\n",
        "\n",
        "# ×—×™×©×•×‘ ×™×—×¡ ×§×‘×œ×ª ×¢×¨×¢×•×¨ ×œ×›×œ ××’×“×¨\n",
        "outcome_counts[\"Total\"] = outcome_counts.sum(axis=1)\n",
        "outcome_counts[\"Acceptance Rate\"] = outcome_counts.get(\"×”×ª×§×‘×œ\", 0) / outcome_counts[\"Total\"]\n",
        "\n",
        "# ×™×¦×™×¨×ª ×’×¨×£ ×©×œ ××—×•×–×™ ×§×‘×œ×ª ×¢×¨×¢×•×¨ ×œ×¤×™ ××’×“×¨\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.barplot(x=outcome_counts.index, y=outcome_counts[\"Acceptance Rate\"])\n",
        "plt.ylabel(\"×©×™×¢×•×¨ ×§×‘×œ×ª ×¢×¨×¢×•×¨\")\n",
        "plt.title(\"×©×™×¢×•×¨ ×§×‘×œ×ª ×¢×¨×¢×•×¨ ×œ×¤×™ ××’×“×¨ ×”×©×•×¤×˜/×ª\")\n",
        "plt.ylim(0, 1)\n",
        "plt.show()\n",
        "\n",
        "# ×”×¦×’×ª ×”×˜×‘×œ×” ×¢× ×”×ª×•×¦××•×ª\n",
        "print(outcome_counts)\n"
      ],
      "metadata": {
        "id": "UiCOhdOnDn7H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oD0_v0cYHx7W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "NBZadrvUE0bf"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oWEkpygnFz8R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bias - number of Judges"
      ],
      "metadata": {
        "id": "n4HEGAa7HeQZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from ast import literal_eval\n",
        "\n",
        "# ×˜×¢×™× ×ª ×”× ×ª×•× ×™×\n",
        "df = check_gender_bias.copy()\n",
        "\n",
        "# ×—×™×©×•×‘ ××¡×¤×¨ ×”×©×•×¤×˜×™× ×‘×›×œ ×ª×™×§\n",
        "df[\"××¡×¤×¨ ×©×•×¤×˜×™×\"] = df[\"××’×“×¨\"].apply(len)\n",
        "\n",
        "# ×—×œ×•×§×ª ×”××§×¨×™× ×œ×©×ª×™ ×§×‘×•×¦×•×ª: ×©×•×¤×˜ ×™×—×™×“ ××• ×™×•×ª×¨ ×××—×“\n",
        "df[\"×™×•×ª×¨ ××©×•×¤×˜ ××—×“\"] = df[\"××¡×¤×¨ ×©×•×¤×˜×™×\"] > 1\n",
        "\n",
        "# ×¡×¤×™×¨×ª ×”××§×¨×™× ×œ×¤×™ ××¡×¤×¨ ×”×©×•×¤×˜×™× ×•×”×× ×”×¢×¨×¢×•×¨ ×”×ª×§×‘×œ\n",
        "outcome_counts = df.groupby(\"×™×•×ª×¨ ××©×•×¤×˜ ××—×“\")[\"×‘×§×©×” ×œ×¨×©×•×ª ×¢×¨×¢×•×¨ ×”×ª×§×‘×œ×”?\"].value_counts(normalize=True).unstack()\n",
        "\n",
        "# ×™×¦×™×¨×ª ×’×¨×£\n",
        "plt.figure(figsize=(8, 5))\n",
        "outcome_counts.plot(kind=\"bar\", stacked=True)\n",
        "plt.ylabel(\"×©×™×¢×•×¨ ×”×¢×¨×¢×•×¨×™× (%)\")\n",
        "plt.title(\"×”×©×¤×¢×ª ××¡×¤×¨ ×”×©×•×¤×˜×™× ×¢×œ ×§×‘×œ×ª ×”×¢×¨×¢×•×¨\")\n",
        "plt.xticks([0, 1], [\"×©×•×¤×˜ ××—×“\", \"×™×•×ª×¨ ××©×•×¤×˜ ××—×“\"], rotation=0)\n",
        "plt.legend(title=\"×ª×•×¦××ª ×”×¢×¨×¢×•×¨\")\n",
        "plt.show()\n",
        "\n",
        "# ×—×™×©×•×‘ ××—×•×– ×§×‘×œ×ª ×¢×¨×¢×•×¨ ×œ×¤×™ ××¡×¤×¨ ×”×©×•×¤×˜×™×\n",
        "acceptance_rate = outcome_counts.get(\"×”×ª×§×‘×œ\", 0)\n",
        "\n",
        "# ×”×“×¤×¡×ª ×¡×˜×˜×™×¡×˜×™×§×”\n",
        "print(\"×©×™×¢×•×¨ ×§×‘×œ×ª ×”×¢×¨×¢×•×¨ ×œ×¤×™ ××¡×¤×¨ ×©×•×¤×˜×™×:\")\n",
        "print(acceptance_rate)\n"
      ],
      "metadata": {
        "id": "tuLNzfE5BBhg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import ast\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy.stats import chi2_contingency\n",
        "\n",
        "df = check_gender_bias.copy()\n",
        "\n",
        "# ×œ×•×•×“× ×©×”×¢××•×“×” '××’×“×¨' ×”×™× ×¨×©×™××” ×•×œ× ××—×¨×•×–×ª\n",
        "df[\"××’×“×¨\"] = df[\"××’×“×¨\"].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n",
        "\n",
        "# ×”×•×¡×¤×ª ×¢××•×“×ª ××¡×¤×¨ ×”×©×•×¤×˜×™× ×‘×›×œ ××§×¨×”\n",
        "df[\"××¡×¤×¨ ×©×•×¤×˜×™×\"] = df[\"××’×“×¨\"].apply(len)\n",
        "\n",
        "# ×™×¦×™×¨×ª ×¢××•×“×ª ××™× ×“×™×§×˜×•×¨ ×× ×”×¢×¨×¢×•×¨ ×”×ª×§×‘×œ ××• ×œ×\n",
        "df[\"×¢×¨×¢×•×¨ ×”×ª×§×‘×œ\"] = df[\"×‘×§×©×” ×œ×¨×©×•×ª ×¢×¨×¢×•×¨ ×”×ª×§×‘×œ×”?\"].apply(lambda x: 1 if x == \"×”×ª×§×‘×œ\" else 0)\n",
        "\n",
        "### ×‘×“×™×§×ª ×”×§×©×¨ ×‘×™×Ÿ ××¡×¤×¨ ×”×©×•×¤×˜×™× ×œ×”×—×œ×˜×” ###\n",
        "grouped_by_judges = df.groupby(\"××¡×¤×¨ ×©×•×¤×˜×™×\")[\"×¢×¨×¢×•×¨ ×”×ª×§×‘×œ\"].mean()\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.barplot(x=grouped_by_judges.index, y=grouped_by_judges.values, palette=\"Blues_r\")\n",
        "plt.xlabel(\"××¡×¤×¨ ×©×•×¤×˜×™×\")\n",
        "plt.ylabel(\"×©×™×¢×•×¨ ×§×‘×œ×ª ×¢×¨×¢×•×¨\")\n",
        "plt.title(\"×”×©×¤×¢×ª ××¡×¤×¨ ×”×©×•×¤×˜×™× ×¢×œ ×§×‘×œ×ª ×”×¢×¨×¢×•×¨\")\n",
        "plt.show()\n",
        "\n",
        "# ×˜×‘×œ×ª ×©×›×™×—×•×ª\n",
        "judge_count_table = df.groupby(\"××¡×¤×¨ ×©×•×¤×˜×™×\")[\"×¢×¨×¢×•×¨ ×”×ª×§×‘×œ\"].value_counts().unstack()\n",
        "print(judge_count_table)\n",
        "\n",
        "# ×‘×“×™×§×” ×¡×˜×˜×™×¡×˜×™×ª - ×”×× ×™×© ×§×©×¨ ××•×‘×”×§ ×‘×™×Ÿ ××¡×¤×¨ ×©×•×¤×˜×™× ×œ×”×—×œ×˜×”\n",
        "chi2, p, _, _ = chi2_contingency(judge_count_table.fillna(0))\n",
        "print(f\"Chi-Square Test: p-value = {p:.4f}\")\n",
        "if p < 0.05:\n",
        "    print(\"××¡×§× ×”: ×§×™×™× ×§×©×¨ ××•×‘×”×§ ×¡×˜×˜×™×¡×˜×™×ª ×‘×™×Ÿ ××¡×¤×¨ ×”×©×•×¤×˜×™× ×œ×§×‘×œ×ª ×”×¢×¨×¢×•×¨.\")\n",
        "else:\n",
        "    print(\"××¡×§× ×”: ××™×Ÿ ×§×©×¨ ××•×‘×”×§ ×¡×˜×˜×™×¡×˜×™×ª ×‘×™×Ÿ ××¡×¤×¨ ×”×©×•×¤×˜×™× ×œ×§×‘×œ×ª ×”×¢×¨×¢×•×¨.\")\n",
        "\n",
        "### ×‘×“×™×§×ª ×‘×™××¡ ××’×“×¨×™ ###\n",
        "# ×—×™×©×•×‘ ××—×•×– ×§×‘×œ×ª ×¢×¨×¢×•×¨ ×œ×¤×™ ××’×“×¨\n",
        "def get_gender_stats(gender_list, outcome):\n",
        "    return any(g in gender_list for g in outcome)\n",
        "\n",
        "df[\"××›×™×œ ×–×›×¨\"] = df[\"××’×“×¨\"].apply(lambda x: \"×–×›×¨\" in x)\n",
        "df[\"××›×™×œ × ×§×‘×”\"] = df[\"××’×“×¨\"].apply(lambda x: \"× ×§×‘×”\" in x)\n",
        "\n",
        "# ×‘×“×™×§×ª ×”×‘×“×œ ×‘×™×Ÿ ××§×¨×™× ×¢× ×œ×¤×—×•×ª ×©×•×¤×˜×ª ×œ×‘×™×Ÿ ××œ×• ×œ×œ×\n",
        "gender_bias_table = df.groupby(\"××›×™×œ × ×§×‘×”\")[\"×¢×¨×¢×•×¨ ×”×ª×§×‘×œ\"].value_counts().unstack()\n",
        "print(\"×˜×‘×œ×ª ×©×›×™×—×•×ª ×œ×¤×™ × ×•×›×—×•×ª ×©×•×¤×˜×•×ª:\\n\", gender_bias_table)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.barplot(x=gender_bias_table.index, y=gender_bias_table[1] / (gender_bias_table[1] + gender_bias_table[0]), palette=\"Reds_r\")\n",
        "plt.xlabel(\"×”×× ×™×© ×œ×¤×—×•×ª ×©×•×¤×˜×ª?\")\n",
        "plt.ylabel(\"×©×™×¢×•×¨ ×§×‘×œ×ª ×¢×¨×¢×•×¨\")\n",
        "plt.title(\"×”×©×¤×¢×ª × ×•×›×—×•×ª ×©×•×¤×˜×ª ×¢×œ ×§×‘×œ×ª ×”×¢×¨×¢×•×¨\")\n",
        "plt.show()\n",
        "\n",
        "# ×‘×“×™×§×” ×¡×˜×˜×™×¡×˜×™×ª - ×”×× ×™×© ×”×‘×“×œ ××•×‘×”×§\n",
        "chi2, p, _, _ = chi2_contingency(gender_bias_table.fillna(0))\n",
        "print(f\"Chi-Square Test for Gender Bias: p-value = {p:.4f}\")\n",
        "if p < 0.05:\n",
        "    print(\"××¡×§× ×”: ×™×© ×¢×“×•×ª ××•×‘×”×§×ª ×œ×›×š ×©× ×•×›×—×•×ª ×©×•×¤×˜×•×ª ××©×¤×™×¢×” ×¢×œ ×”×—×œ×˜×ª ×”×¢×¨×¢×•×¨.\")\n",
        "else:\n",
        "    print(\"××¡×§× ×”: ××™×Ÿ ×¢×“×•×ª ××•×‘×”×§×ª ×œ×›×š ×©× ×•×›×—×•×ª ×©×•×¤×˜×•×ª ××©×¤×™×¢×” ×¢×œ ×”×—×œ×˜×ª ×”×¢×¨×¢×•×¨.\")\n"
      ],
      "metadata": {
        "id": "FMphMwfMI3Sg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(dataframes)"
      ],
      "metadata": {
        "id": "cPRCkVSd61os"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_1 = dataframes[0].copy()\n",
        "\n",
        "df_1.columns"
      ],
      "metadata": {
        "id": "5Rv2ZUDm8Dk6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_1 = df_1[['×’×•×£ ×”××¡××š', '××¡×¤×¨ ×”×œ×™×š', '×©× ×”×œ×™×š',\n",
        "       '×©× ×ª ×¤×ª×™×—×ª ×”×”×œ×™×š', '×’×•×£ ×”××¡××š ×—×ª×•×š',  '×‘×§×©×” ×œ×¨×©×•×ª ×¢×¨×¢×•×¨ ×”×ª×§×‘×œ×”?',\n",
        "       '×˜×§×¡×˜ ×©××¦×‘×™×¢ ×¢×œ ×ª×•×¦××ª ×‘×§×©×” ×©×•× ×”', '×”×¢×¨×¢×•×¨ ×”×ª×§×‘×œ?',\n",
        "       '×¨×¢\"×¤ ×‘×§×©×” ××—×¨×ª ××• ×“×œ××˜×” ××™×•×—×“', '×”×¢×¨×•×ª ',\n",
        "       '×”×¢×¨×•×ª ×§×™×“×•×“ ×—×•×–×¨']]"
      ],
      "metadata": {
        "id": "DY_3qlUc-I43"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_2 = dataframes[1].copy()"
      ],
      "metadata": {
        "id": "uawB3EtE-t8N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_2 = df_2[['×’×•×£ ×”××¡××š', '××¡×¤×¨ ×”×œ×™×š', '×©× ×”×œ×™×š',\n",
        "       '×©× ×ª ×¤×ª×™×—×ª ×”×”×œ×™×š', '×’×•×£ ×”××¡××š ×—×ª×•×š',\n",
        "       '×‘×§×©×” ×œ×¨×©×•×ª ×¢×¨×¢×•×¨ ×”×ª×§×‘×œ×”?',\n",
        "       '×˜×§×¡×˜ ×©××¦×‘×™×¢ ×¢×œ ×ª×•×¦××ª ×‘×§×©×” ×©×•× ×” (×˜×§×¡×˜×™× ×©×•× ×™× ××•×¤×¨×“×™× ×‘-**)',\n",
        "       '×”×¢×¨×¢×•×¨ ×”×ª×§×‘×œ?', '×¨×¢\"×¤ ×‘×§×©×” ××—×¨×ª ××• ×“×œ××˜×” ××™×•×—×“',\n",
        "       '×”×¢×¨×•×ª ×ª×•×¦××ª ×¢×¨×¢×•×¨', '×”×¢×¨×•×ª ', '×”×¢×¨×•×ª ×§×™×“×•×“ ×—×•×–×¨']]"
      ],
      "metadata": {
        "id": "JXniQQU3-2Gz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.concat([df_1, df_2], ignore_index=True)"
      ],
      "metadata": {
        "id": "z0NIHaoM_lDF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_3 = dataframes[2].copy()"
      ],
      "metadata": {
        "id": "GTp1f9y2_G3l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_3 = df_3[['×’×•×£ ×”××¡××š', '××¡×¤×¨ ×”×œ×™×š', '×©× ×”×œ×™×š',\n",
        "       '×©× ×ª ×¤×ª×™×—×ª ×”×”×œ×™×š',\n",
        "       '×‘×§×©×” ×œ×¨×©×•×ª ×¢×¨×¢×•×¨ ×”×ª×§×‘×œ×”?',\n",
        "       '×˜×§×¡×˜ ×©××¦×‘×™×¢ ×¢×œ ×ª×•×¦××ª ×‘×§×©×” ×©×•× ×” (×˜×§×¡×˜×™× ×©×•× ×™× ××•×¤×¨×“×™× ×‘-**)',\n",
        "       '×”×¢×¨×¢×•×¨ ×”×ª×§×‘×œ?', '×”×¢×¨×•×ª ×ª×•×¦××ª ×¢×¨×¢×•×¨', '×¨×¢\"×¤ ×‘×§×©×” ××—×¨×ª ××• ×“×œ××˜×” ××™×•×—×“', '×”×¢×¨×•×ª ']]"
      ],
      "metadata": {
        "id": "KY4yog2-_usH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.concat([df, df_3], ignore_index=True)"
      ],
      "metadata": {
        "id": "VVsLDIhj_G71"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zmxYCBBC_B2h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "columns_to_check = [\n",
        "    \"×”×¢×¨×•×ª \",\n",
        "    \"×”×¢×¨×•×ª ×ª×•×¦××ª ×¢×¨×¢×•×¨\",\n",
        "    \"×”×¢×¨×•×ª ×§×™×“×•×“ ×—×•×–×¨\",\n",
        "    \"×˜×§×¡×˜ ×©××¦×‘×™×¢ ×¢×œ ×ª×•×¦××ª ×‘×§×©×” ×©×•× ×”\",\n",
        "    \"×˜×§×¡×˜ ×©××¦×‘×™×¢ ×¢×œ ×ª×•×¦××ª ×‘×§×©×” ×©×•× ×” (×˜×§×¡×˜×™× ×©×•× ×™× ××•×¤×¨×“×™× ×‘-**)\",\n",
        "    \"×˜×§×¡×˜ ×©××¦×‘×™×¢ ×¢×œ ×ª×•×¦××ª ×‘×§×©×” ×©×•× ×” (×˜×§×¡×˜×™× ×©×•× ×™× ××•×¤×¨×“×™× ×‘-**)\"\n",
        "]\n",
        "\n",
        "\n",
        "df = df[~df[columns_to_check].isna().all(axis=1)]"
      ],
      "metadata": {
        "id": "HYPwg-TeAoWD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "yBNrZ9ST4YK_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jQd6gOcv_C0u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IQTmuq1v_c1J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SKArgzv3_lC5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(df[\"×’×•×£ ×”××¡××š\"])\n",
        "\n",
        "df[\"length\"] = df[\"×’×•×£ ×”××¡××š\"].apply(lambda x: len(str(x).split()))\n",
        "\n",
        "average_length = df[\"length\"].mean()\n",
        "max_length = df[\"length\"].max()\n",
        "min_length = df[\"length\"].min()\n",
        "\n",
        "print(f\"××•×¨×š ×××•×¦×¢ ×©×œ ×¤×¡×§×™ ×“×™×Ÿ: {average_length:.2f} ××™×œ×™×\")\n",
        "print(f\"×¤×¡×§ ×”×“×™×Ÿ ×”××¨×•×š ×‘×™×•×ª×¨ ××›×™×œ {max_length} ××™×œ×™×\")\n",
        "print(f\"×¤×¡×§ ×”×“×™×Ÿ ×”×§×¦×¨ ×‘×™×•×ª×¨ ××›×™×œ {min_length} ××™×œ×™×\")\n"
      ],
      "metadata": {
        "id": "KEkZ-UDy4gbv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_list_to_string(text):\n",
        "    if isinstance(text, str) and text.startswith(\"[\") and text.endswith(\"]\"):\n",
        "        try:\n",
        "            text_list = ast.literal_eval(text)\n",
        "            return ' '.join(text_list)\n",
        "        except (ValueError, SyntaxError):\n",
        "            return text\n",
        "    return text\n",
        "\n",
        "def clean_text(text):\n",
        "    if isinstance(text, list):\n",
        "        text = ' '.join(text)\n",
        "    elif isinstance(text, str):\n",
        "        text = re.sub(r'\\n+', ' ', text)  # ×”×¡×¨×ª ×©×•×¨×•×ª ×—×“×©×•×ª ××¨×•×‘×•×ª\n",
        "        text = re.sub(r'\\n', '', text)   # ×”×¡×¨×ª ×ª×•×•×™ newline \\n ××”×˜×§×¡×˜\n",
        "        text = re.sub(r'\\xa0', ' ', text)  # ×”×¡×¨×ª ×ª×•×•×™ \\xa0 ××”×˜×§×¡×˜\n",
        "        text = re.sub(r'\\s+', ' ', text)  # ×”×¡×¨×ª ×¨×•×•×—×™× ××¨×•×‘×™×\n",
        "\n",
        "        text = re.sub(r\"×”×¢×•×ª×§ ×›×¤×•×£ ×œ×©×™× ×•×™×™ ×¢×¨×™×›×” ×•× ×™×¡×•×—.*?$\", \"\", text, flags=re.MULTILINE)\n",
        "        text = re.sub(r\"××¨×›×– ××™×“×¢, ×˜×œ' \\d{2,3}-\\d{6,7}.*?$\", \"\", text, flags=re.MULTILINE)\n",
        "        text = re.sub(r\"××ª×¨ ××™× ×˜×¨× ×˜, .*?$\", \"\", text, flags=re.MULTILINE)\n",
        "    return text\n",
        "\n",
        "print(\"×©×•×¨×•×ª ×œ× ×§×¨×™××•×ª ×œ×¤× ×™ ×”××¨×”:\")\n",
        "print(df[\"×’×•×£ ×”××¡××š\"].head())\n",
        "\n",
        "df[\"×’×•×£ ×”××¡××š\"] = df[\"×’×•×£ ×”××¡××š\"].apply(clean_text)\n",
        "\n",
        "print(\"\\n×©×•×¨×•×ª ×œ××—×¨ ×”××¨×”:\")\n",
        "print(df[\"×’×•×£ ×”××¡××š\"].head())\n",
        "\n",
        "file_path_full = 'checked_df_cleaned.csv' # FULL RAP DATA CLEANED\n",
        "df.to_csv(file_path_full, index=False, encoding='utf-8')\n"
      ],
      "metadata": {
        "id": "lLLLzAUR6XvO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_relevant_part(text):\n",
        "    words = str(text).split()\n",
        "    if len(words) > 1000:\n",
        "        return \" \".join(words[-800:-20])\n",
        "    return text\n",
        "\n",
        "df[\"×’×•×£ ×”××¡××š ×—×ª×•×š\"] = df[\"×’×•×£ ×”××¡××š\"].apply(extract_relevant_part)\n",
        "\n",
        "df[[\"×’×•×£ ×”××¡××š\", \"×’×•×£ ×”××¡××š ×—×ª×•×š\"]].head()\n"
      ],
      "metadata": {
        "id": "997LkOwE5bcg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yI75UNYF-8eD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df[['×’×•×£ ×”××¡××š', '××¡×¤×¨ ×”×œ×™×š', '×©× ×”×œ×™×š', '×©× ×ª ×¤×ª×™×—×ª ×”×”×œ×™×š',\n",
        "       '×’×•×£ ×”××¡××š ×—×ª×•×š', '×‘×§×©×” ×œ×¨×©×•×ª ×¢×¨×¢×•×¨ ×”×ª×§×‘×œ×”?',\n",
        "       '×˜×§×¡×˜ ×©××¦×‘×™×¢ ×¢×œ ×ª×•×¦××ª ×‘×§×©×” ×©×•× ×”', '×”×¢×¨×¢×•×¨ ×”×ª×§×‘×œ?',\n",
        "       '×¨×¢\"×¤ ×‘×§×©×” ××—×¨×ª ××• ×“×œ××˜×” ××™×•×—×“', '×”×¢×¨×•×ª ', '×”×¢×¨×•×ª ×§×™×“×•×“ ×—×•×–×¨',\n",
        "       '×˜×§×¡×˜ ×©××¦×‘×™×¢ ×¢×œ ×ª×•×¦××ª ×‘×§×©×” ×©×•× ×” (×˜×§×¡×˜×™× ×©×•× ×™× ××•×¤×¨×“×™× ×‘-**)',\n",
        "       '×”×¢×¨×•×ª ×ª×•×¦××ª ×¢×¨×¢×•×¨', 'length',]]"
      ],
      "metadata": {
        "id": "2SuWC1ad7GuW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns = df.columns.str.strip()\n",
        "df.columns = df.columns.str.replace(\"\\n\", \"\")\n",
        "df.columns = df.columns.str.replace(\"  \", \" \")"
      ],
      "metadata": {
        "id": "yAKcKxV--dai"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.rename(columns={\n",
        "    '×”×¢×¨×•×ª ':\"×”×¢×¨×•×ª\",\n",
        "    '×˜×§×¡×˜ ×©××¦×‘×™×¢ ×¢×œ ×ª×•×¦××ª ×‘×§×©×” ×©×•× ×”':\"×˜×§×¡×˜ ×©××¦×‘×™×¢ ×¢×œ ×ª×•×¦××ª ×‘×§×©×”\",\n",
        "    \"×˜×§×¡×˜ ×©××¦×‘×™×¢ ×¢×œ ×ª×•×¦××ª ×‘×§×©×” ×©×•× ×” (×˜×§×¡×˜×™× ×©×•× ×™× ××•×¤×¨×“×™× ×‘-**)\": \"×˜×§×¡×˜ ×©××¦×‘×™×¢ ×¢×œ ×”×ª×•×¦××”\"\n",
        "}, inplace=True)\n",
        "\n",
        "df.columns\n"
      ],
      "metadata": {
        "id": "kdd6KMu89uSk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "columns_to_merge = [\n",
        "    '×˜×§×¡×˜ ×©××¦×‘×™×¢ ×¢×œ ×ª×•×¦××ª ×‘×§×©×”',\n",
        "    '×¨×¢\"×¤ ×‘×§×©×” ××—×¨×ª ××• ×“×œ××˜×” ××™×•×—×“',  \"×”×¢×¨×•×ª\", '×”×¢×¨×•×ª ×§×™×“×•×“ ×—×•×–×¨',\n",
        "    \"×˜×§×¡×˜ ×©××¦×‘×™×¢ ×¢×œ ×”×ª×•×¦××”\",\n",
        "    '×”×¢×¨×•×ª ×ª×•×¦××ª ×¢×¨×¢×•×¨'\n",
        "]\n",
        "\n",
        "def clean_merge_columns(row, columns):\n",
        "    values = []\n",
        "    for col in columns:\n",
        "        if pd.notna(row[col]) and str(row[col]).strip():\n",
        "            text = f\"{str(row[col]).strip()}\"\n",
        "            text.replace(\"?\", \"\")\n",
        "            text\n",
        "            text = re.sub(r\"×”×¢×¨×” ×©×œ \\S+\\s*\", \"\", text)\n",
        "            values.append(text)\n",
        "\n",
        "    return \"\\n\".join(values) if values else None\n",
        "\n",
        "# ×™×¦×™×¨×ª ×¢××•×“×” ×××•×—×“×ª ×¢× ×›×•×ª×¨×•×ª ×œ×›×œ ×¢×¨×š\n",
        "df[\"×ª×•×¦××” ××¡×›××ª\"] = df.apply(lambda row: clean_merge_columns(row, columns_to_merge), axis=1)\n",
        "\n",
        "\n",
        "# ×”×¦×’×ª ××¡×¤×¨ ×“×•×’×××•×ª ×œ×‘×“×™×§×”\n",
        "df[[\"×ª×•×¦××” ××¡×›××ª\"]].head()\n"
      ],
      "metadata": {
        "id": "SIeNQC_W8IBy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for i in range(3):\n",
        "    print(f\"×¤×¡×§ ×“×™×Ÿ {i+1} (×ª×•×¦××” ××¡×›××ª):\\n\")\n",
        "    print(df[\"×ª×•×¦××” ××¡×›××ª\"].iloc[i])\n",
        "    print(\"=\"*80)\n"
      ],
      "metadata": {
        "id": "bqBlYGtW7B_u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('display.max_colwidth', None)\n",
        "\n",
        "df[[\"×’×•×£ ×”××¡××š ×—×ª×•×š\", \"×ª×•×¦××” ××¡×›××ª\"]].sample(5, random_state=42)"
      ],
      "metadata": {
        "id": "3sAWoccf8nIb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[[\"×’×•×£ ×”××¡××š ×—×ª×•×š\", \"×ª×•×¦××” ××¡×›××ª\"]].sample(5, random_state=42)"
      ],
      "metadata": {
        "id": "mIGeDoOU8nNx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_excel(\"/content/dataframe_cleaned.xlsx\", index=False)"
      ],
      "metadata": {
        "id": "sWN2TicK8nF6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# split - train, validation, test"
      ],
      "metadata": {
        "id": "DvkoVz9nl7qx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, temp_data = train_test_split(df, test_size=0.2, random_state=42)\n",
        "valid_data, test_data = train_test_split(temp_data, test_size=0.5, random_state=42)\n",
        "\n",
        "def convert_to_jsonl(data, filename):\n",
        "    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
        "        for _, row in data.iterrows():\n",
        "            json.dump({\n",
        "                \"messages\": [\n",
        "                    {\"role\": \"system\", \"content\": \"××ª×” ×¢×•×–×¨ ××©×¤×˜×™ ×œ× ×™×ª×•×— ×¤×¡×§×™ ×“×™×Ÿ ××¡×•×’ ×¨×¢\\\"×¤\"},\n",
        "                    {\"role\": \"user\", \"content\": row[\"×’×•×£ ×”××¡××š ×—×ª×•×š\"]},\n",
        "                    {\"role\": \"assistant\", \"content\": row[\"×ª×•×¦××” ××¡×›××ª\"]}\n",
        "                ]\n",
        "            }, f, ensure_ascii=False)\n",
        "            f.write(\"\\n\")\n",
        "\n",
        "convert_to_jsonl(train_data, \"train.jsonl\")\n",
        "convert_to_jsonl(valid_data, \"valid.jsonl\")\n",
        "convert_to_jsonl(test_data, \"test.jsonl\")\n"
      ],
      "metadata": {
        "id": "-bvQXAHkypbm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fine tune Llama 2 using LoRA"
      ],
      "metadata": {
        "id": "trxAYL0pM2fe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from huggingface_hub import login\n",
        "# from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "# import json\n",
        "# from peft import LoraConfig, get_peft_model, TaskType\n",
        "# from transformers import TrainingArguments, Trainer"
      ],
      "metadata": {
        "id": "QA46zLkn0dE7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# with open(\"/content/Llama_login.txt\", \"r\") as file:\n",
        "#   llama_login = file.read().strip()\n",
        "\n",
        "# login(llama_login)\n",
        "\n",
        "# MODEL_NAME = \"meta-llama/Llama-2-7b-chat-hf\"\n",
        "\n",
        "# tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_auth_token=True)\n",
        "# model = AutoModelForCausalLM.from_pretrained(MODEL_NAME, torch_dtype=\"auto\", device_map=\"auto\", use_auth_token=True)\n",
        "\n",
        "# print(\"ğŸ¯ ×”××•×“×œ × ×˜×¢×Ÿ ×‘×”×¦×œ×—×”!\")\n"
      ],
      "metadata": {
        "id": "e9nziHo7OYqg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def generate_summary_llama2(case_text):\n",
        "#     input_ids = tokenizer(case_text, return_tensors=\"pt\").input_ids.to(\"cuda\")\n",
        "#     output = model.generate(input_ids, max_new_tokens=100)\n",
        "#     return tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "\n",
        "# # ×‘×•×“×§×™× ×¤×¡×§ ×“×™×Ÿ ×œ×“×•×’××”\n",
        "# sample_case = dataset[\"valid\"][0][\"messages\"][1][\"content\"]\n",
        "# llama2_summary = generate_summary_llama2(sample_case)\n",
        "\n",
        "# print(llama2_summary)\n"
      ],
      "metadata": {
        "id": "P1nOtQI51LNd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aZWwNNhE4k95"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test_text = \"×¤×¡×§ ×“×™×Ÿ ××©×¤×˜×™ ×œ×“×•×’××” ×¢×œ ×¡×›×¡×•×š ××–×¨×—×™\"\n",
        "# input_ids = tokenizer(test_text, return_tensors=\"pt\").input_ids.to(\"cuda\")\n",
        "\n",
        "# output = model.generate(input_ids, max_new_tokens=100)\n",
        "# generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "\n",
        "# print(\"×¤×œ×˜ ×”××•×“×œ ×œ×œ× Fine-Tuning:\\n\", generated_text)\n"
      ],
      "metadata": {
        "id": "S8GBbJ7m3mTS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def generate_summary_llama2(case_text):\n",
        "#     prompt = (\n",
        "#         \"×¡×›× ××ª ×¤×¡×§ ×”×“×™×Ÿ ×”×‘× ×‘×¦×•×¨×” ×ª××¦×™×ª×™×ª:\\n\\n\"\n",
        "#         f\"{case_text}\\n\\n\"\n",
        "#         \"×¡×™×›×•× ××©×¤×˜×™: \"\n",
        "#     )\n",
        "#     input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(\"cuda\")\n",
        "#     output = model.generate(input_ids, max_new_tokens=100)\n",
        "#     return tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "\n",
        "\n",
        "# llama2_summary = generate_summary_llama2(sample_case)\n",
        "# print(\"×¡×™×›×•× ××©×•×¤×¨ ×¢×œ ×™×“×™ Llama 2:\", llama2_summary)\n"
      ],
      "metadata": {
        "id": "xim3_RSeMz7d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GPT Fine tuning"
      ],
      "metadata": {
        "id": "sQs5YfJclw-_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# with open(\"/content/api_key.txt\", \"r\") as file:\n",
        "#     api_key = file.read().strip()\n",
        "\n",
        "# client = openai.OpenAI(api_key=api_key)\n",
        "\n",
        "# train_file = client.files.create(\n",
        "#     file=open(\"train.jsonl\", \"rb\"),\n",
        "#     purpose=\"fine-tune\"\n",
        "# )\n",
        "\n",
        "# print(\"Train File ID:\", train_file.id)"
      ],
      "metadata": {
        "id": "aIVvqpF7B5j-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# files = client.files.list()\n",
        "# print(files)"
      ],
      "metadata": {
        "id": "wv5HKJP8QAWN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fine_tune = client.fine_tuning.jobs.create(\n",
        "#     training_file=train_file.id,\n",
        "#     model=\"gpt-3.5-turbo\"\n",
        "# )\n",
        "\n",
        "# print(\"Fine-Tuning Job ID:\", fine_tune.id)"
      ],
      "metadata": {
        "id": "surRCAvEQEYC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fine_tune_status = client.fine_tuning.jobs.retrieve(fine_tune.id)\n",
        "# print(fine_tune_status)"
      ],
      "metadata": {
        "id": "8qqWR0MtQPb-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# job_id = fine_tune_status.id\n",
        "# while True:\n",
        "#     fine_tune_job = client.fine_tuning.jobs.retrieve(job_id)\n",
        "#     print(f\"Status: {fine_tune_job.status}\")\n",
        "\n",
        "#     if fine_tune_job.status in [\"succeeded\", \"failed\", \"cancelled\"]:\n",
        "#         print(f\"Fine-Tuned Model ID: {fine_tune_job.fine_tuned_model}\")\n",
        "#         break\n",
        "\n",
        "#     time.sleep(60*5)"
      ],
      "metadata": {
        "id": "GVzAVhHfQ-nS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# print(fine_tune_job.trained_tokens)\n",
        "# print(fine_tune_job.fine_tuned_model)"
      ],
      "metadata": {
        "id": "MKax7TTrQqsn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Save the fine-tuned model ID in a text file (only needs to be done once)\n",
        "# with open(\"/content/fine_tuned_model.txt\", \"w\") as file:\n",
        "#     file.write(fine_tune_job.fine_tuned_model)\n"
      ],
      "metadata": {
        "id": "pF6oKBjFtPkg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# result_files = client.files.list()\n",
        "# for file in result_files.data:\n",
        "#     if \"fine-tuning\" in file.purpose:\n",
        "#         print(file.filename, file.id)"
      ],
      "metadata": {
        "id": "Y75Vbz6sQxLf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# response = client.chat.completions.create(\n",
        "#     model=fine_tune_job.fine_tuned_model,\n",
        "#     messages=[\n",
        "#         {\"role\": \"system\", \"content\": '××ª×” ××•××—×” ××©×¤×˜×™ ×œ× ×™×ª×•×— ×•×ª××¦×•×ª ×©×•×¨×” ×ª×—×ª×•× ×” ×©×œ ×¤×¡×§×™ ×“×™×Ÿ ××¡×•×’ ×¨×¢\"×¤'},\n",
        "#         {\"role\": \"user\", \"content\": test_data.iloc[0][\"×’×•×£ ×”××¡××š ×—×ª×•×š\"]}\n",
        "#     ]\n",
        "# )\n",
        "\n",
        "# print(\"×ª×©×•×‘×” ×©×”××•×“×œ × ×ª×Ÿ:\")\n",
        "# print(response.choices[0].message.content)\n",
        "\n",
        "# print(\"×ª×•×¦××” ××§×•×¨×™×ª:\\n\")\n",
        "# print(test_data.iloc[0][\"×ª×•×¦××” ××¡×›××ª\"])\n"
      ],
      "metadata": {
        "id": "aRWCn-FFnE61"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for i in range(len(test_data)):\n",
        "#   response = client.chat.completions.create(\n",
        "#     model=fine_tune_job.fine_tuned_model,\n",
        "#     messages=[\n",
        "#         {\"role\": \"system\", \"content\": '××ª×” ××•××—×” ××©×¤×˜×™ ×œ× ×™×ª×•×— ×•×ª××¦×•×ª ×©×•×¨×” ×ª×—×ª×•× ×” ×©×œ ×¤×¡×§×™ ×“×™×Ÿ ××¡×•×’ ×¨×¢\"×¤'},\n",
        "#         {\"role\": \"user\", \"content\": test_data.iloc[i][\"×’×•×£ ×”××¡××š ×—×ª×•×š\"]}\n",
        "#     ]\n",
        "#   )\n",
        "#   print(f\"××¡××š ××¡×¤×¨ {i+1}:\")\n",
        "#   print(\"×¤×¡×§ ×“×™×Ÿ:\")\n",
        "#   print(test_data.iloc[i][\"×’×•×£ ×”××¡××š ×—×ª×•×š\"])\n",
        "\n",
        "#   print(\"×ª×©×•×‘×” ×©×”××•×“×œ × ×ª×Ÿ:\")\n",
        "#   print(response.choices[0].message.content)\n",
        "\n",
        "#   print(\"×ª×•×¦××” ××§×•×¨×™×ª:\")\n",
        "#   print(test_data.iloc[i][\"×ª×•×¦××” ××¡×›××ª\"])\n",
        "\n",
        "#   print(\"-------------------------------\")"
      ],
      "metadata": {
        "id": "QyoNDWY3xL9A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GPT - Evaluation"
      ],
      "metadata": {
        "id": "thNQeKO5sGpn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.merge(df, check_gender_bias, on=\"××¡×¤×¨ ×”×œ×™×š\", how=\"left\", suffixes=('', '_dup'))\n",
        "\n",
        "df = df.loc[:, ~df.columns.str.endswith('_dup')]\n"
      ],
      "metadata": {
        "id": "jknPah_8NoFc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "IIvYn9i7P1MO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import json\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.stats as stats\n",
        "import ast\n",
        "\n",
        "\n",
        "with open(\"/content/api_key.txt\", \"r\") as file:\n",
        "    api_key = file.read().strip()\n",
        "\n",
        "client = openai.OpenAI(api_key=api_key)\n"
      ],
      "metadata": {
        "id": "DazRrJnLS5Z_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Fetch all fine-tuned models\n",
        "fine_tuned_models = client.fine_tuning.jobs.list()\n",
        "\n",
        "# Extract the most recent fine-tuned model ID\n",
        "latest_model = None\n",
        "for model in fine_tuned_models:\n",
        "    if model.status == \"succeeded\":  # Making sure it's fully trained\n",
        "        latest_model = model.fine_tuned_model\n",
        "        break\n",
        "\n",
        "if latest_model:\n",
        "    print(\"Using Fine-Tuned Model\")\n",
        "else:\n",
        "    print(\"No fine-tuned model found.\")\n"
      ],
      "metadata": {
        "id": "rN8x3pMhtaEF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Ensure '××’×“×¨' column is properly formatted as a list\n",
        "def safe_eval(value):\n",
        "    \"\"\" Convert string representation of a list to an actual list safely. \"\"\"\n",
        "    if isinstance(value, str):\n",
        "        try:\n",
        "            return ast.literal_eval(value)  # Convert string to list\n",
        "        except (SyntaxError, ValueError):\n",
        "            return None  # If conversion fails, return None\n",
        "    elif isinstance(value, list):\n",
        "        return value\n",
        "    else:\n",
        "        return None  # If it's NaN or other type, return None\n",
        "\n",
        "df[\"××’×“×¨\"] = df[\"××’×“×¨\"].apply(safe_eval)\n",
        "\n",
        "# Drop rows where we don't have judge information\n",
        "df = df[df[\"××’×“×¨\"].notna()]\n",
        "\n",
        "# Create a new column for number of judges\n",
        "df[\"num_judges\"] = df[\"××’×“×¨\"].apply(len)\n",
        "\n",
        "\n",
        "df = df[df[\"num_judges\"] > 0]\n",
        "\n",
        "\n",
        "# Count occurrences of appeal acceptance based on number of judges\n",
        "real_counts = df.groupby(\"num_judges\")[\"×‘×§×©×” ×œ×¨×©×•×ª ×¢×¨×¢×•×¨ ×”×ª×§×‘×œ×”?\"].value_counts().unstack().fillna(0)\n",
        "\n",
        "# Plot real data\n",
        "plt.figure(figsize=(10, 6))\n",
        "real_counts.div(real_counts.sum(axis=1), axis=0).plot(kind=\"bar\", stacked=True, colormap=\"Reds_r\")\n",
        "plt.title(\"Actual Appeal Acceptance Rate by Number of Judges\")\n",
        "plt.xlabel(\"Number of Judges\")\n",
        "plt.ylabel(\"Proportion\")\n",
        "plt.xticks(rotation=0)\n",
        "plt.legend(title=\"Appeal Outcome\")\n",
        "plt.show()\n",
        "\n",
        "# Chi-Square test to check statistical significance\n",
        "chi2, p_value, _, _ = stats.chi2_contingency(real_counts)\n",
        "print(f\"Chi-Square Test: p-value = {p_value:.4f}\")\n",
        "\n",
        "# Interpretation\n",
        "if p_value > 0.05:\n",
        "    print(\"No statistically significant relationship between the number of judges and appeal acceptance.\")\n",
        "else:\n",
        "    print(\"A statistically significant relationship exists between the number of judges and appeal acceptance.\")\n"
      ],
      "metadata": {
        "id": "9uoYNHxKN_ce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AnjBS-jpTVV7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to ask GPT to explain its reasoning\n",
        "def gpt_explain_patterns(case_text):\n",
        "    response = client.chat.completions.create(\n",
        "        model=latest_model,\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\":\"××ª×” ××•××—×” ××©×¤×˜×™. ×”×¡×‘×¨ ××ª ×”× ×™××•×§×™× ×××—×•×¨×™ ×”×”×—×œ×˜×” ×‘××§×¨×” ×”× ×ª×•×Ÿ.\"},\n",
        "            {\"role\": \"user\", \"content\": f\"Case: {case_text}\\n\\n××”× ×”×’×•×¨××™× ×”××¨×›×–×™×™× ×”××©×¤×™×¢×™× ×¢×œ ×”×”×—×œ×˜×”?\"}\n",
        "        ]\n",
        "    )\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "# Apply GPT explanation function\n",
        "df[\"model_patterns\"] = df[\"×‘×§×©×” ×œ×¨×©×•×ª ×¢×¨×¢×•×¨ ×”×ª×§×‘×œ×”?\"].apply(lambda x: gpt_explain_patterns(x))\n",
        "\n",
        "# Display examples of patterns extracted by GPT\n",
        "print(df[[\"×‘×§×©×” ×œ×¨×©×•×ª ×¢×¨×¢×•×¨ ×”×ª×§×‘×œ×”?\", \"model_patterns\"]].head())\n"
      ],
      "metadata": {
        "id": "tC1vY02iSr0P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import lime\n",
        "import lime.lime_text\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import openai\n",
        "\n",
        "\n",
        "# Prepare dataset for analysis\n",
        "X_text = df[\"×‘×§×©×” ×œ×¨×©×•×ª ×¢×¨×¢×•×¨ ×”×ª×§×‘×œ×”?\"].astype(str)\n",
        "\n",
        "# Create a simple TF-IDF model to analyze textual patterns\n",
        "vectorizer = TfidfVectorizer()\n",
        "X_tfidf = vectorizer.fit_transform(X_text)\n",
        "\n",
        "# Train a simple classifier to act as a proxy for GPT\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "clf = LogisticRegression()\n",
        "clf.fit(X_tfidf, df[\"×‘×§×©×” ×œ×¨×©×•×ª ×¢×¨×¢×•×¨ ×”×ª×§×‘×œ×”?\"])\n",
        "\n",
        "# Use LIME to explain what influences GPT's decisions\n",
        "explainer = lime.lime_text.LimeTextExplainer(class_names=[\"Rejected\", \"Accepted\"])\n",
        "idx = 0  # Choose an index to explain\n",
        "\n",
        "exp = explainer.explain_instance(\n",
        "    X_text.iloc[idx],\n",
        "    clf.predict_proba,\n",
        "    num_features=10\n",
        ")\n",
        "\n",
        "# Show LIME explanation\n",
        "exp.show_in_notebook()\n"
      ],
      "metadata": {
        "id": "HMcQif70NoOd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load test dataset\n",
        "def load_jsonl(filename):\n",
        "    with open(filename, \"r\", encoding=\"utf-8\") as f:\n",
        "        return [json.loads(line) for line in f]\n",
        "\n",
        "test_data = load_jsonl(\"test.jsonl\")"
      ],
      "metadata": {
        "id": "geq-TedN50BA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fairness"
      ],
      "metadata": {
        "id": "dkOKjhBEuWWU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Function to evaluate factuality (Faithfulness)\n",
        "def evaluate_factuality(original_text, generated_summary):\n",
        "    response = client.chat.completions.create(\n",
        "        model=latest_model,\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": '××ª×” ××•××—×” ××©×¤×˜×™. ×“×¨×’ ××ª ××™×“×ª ×”× ××× ×•×ª ×©×œ ×”×ª×§×¦×™×¨ ×œ×¤×¡×§ ×”×“×™×Ÿ ×”××§×•×¨×™ ×‘×¡×•×œ× ×©×œ 1-5, ×›××©×¨ 5 ×”×•× ×”× ××× ×•×ª ×”×’×‘×•×”×” ×‘×™×•×ª×¨.'},\n",
        "            {\"role\": \"user\", \"content\": f\"×¤×¡×§ ×“×™×Ÿ: {original_text}\\n\\n×¡×™×›×•×: {generated_summary}\\n\\n×¢×“ ×›××” ×”×¡×™×›×•× ××“×•×™×§ ×•× ×××Ÿ ×œ××§×•×¨?\"}\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "# Evaluate on test data\n",
        "for i, case in enumerate(test_data[:5]):  # Running on the first 5 cases\n",
        "    original_text = case[\"messages\"][1][\"content\"]\n",
        "    generated_summary = case[\"messages\"][2][\"content\"]\n",
        "\n",
        "    faithfulness_score = evaluate_factuality(original_text, generated_summary)\n",
        "\n",
        "    print(f\"Case {i+1}:\")\n",
        "    print(\"Original Judgment:\", original_text)\n",
        "    print(\"Generated Summary:\", generated_summary)\n",
        "    print(\"Faithfulness Score:\", faithfulness_score)\n",
        "    print(\"-------------------------------------------------\")\n"
      ],
      "metadata": {
        "id": "zCHXUvfh7nbb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "×”××•×“×œ ×œ× ××•×¡×™×£ ××• ××©× ×” ××™×“×¢ ×§×¨×™×˜×™.\n",
        "\n",
        "×©×™×¤×•×¨ ××¤×©×¨×™ -\n",
        "1. ×”×•×¡×¤×ª PENALTY ×œ××•×“×œ ×¢×œ ×”×©××˜×” ×©×œ ××™×“×¢ ××”×•×ª×™. ×œ××©×œ ×× ×”×¢×¨×¢×•×¨ ××ª×§×‘×œ ×—×œ×§×™×ª ×•×”××•×“×œ ×˜×•×¢×Ÿ ×©× ×“×—×” ×œ×’××¨×™.\n",
        "2. ×—×™×‘×•×¨ ×œRAG - ×›×“×™ ×œ×× ×•×¢ ×¢×•×“ ×˜×¢×•×™×•×ª (×××’×¨ ××©×¤×˜×™ × ×•×¡×£)"
      ],
      "metadata": {
        "id": "mOR-g9qg6dux"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Bias"
      ],
      "metadata": {
        "id": "avLNRRMguxps"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shap\n",
        "\n",
        "# Function to check SHAP (explainability)\n",
        "def explain_shap(case_text):\n",
        "    explainer = shap.Explainer(client.chat.completions.create)\n",
        "    shap_values = explainer([case_text])\n",
        "    return shap_values\n",
        "\n",
        "# Function to check Counterfactual Fairness\n",
        "def check_bias(input_text, changed_text):\n",
        "    response_base = client.chat.completions.create(\n",
        "        model=latest_model,\n",
        "        messages=[{\"role\": \"user\", \"content\": input_text}]\n",
        "    )\n",
        "\n",
        "    response_changed = client.chat.completions.create(\n",
        "        model=latest_model,\n",
        "        messages=[{\"role\": \"user\", \"content\": changed_text}]\n",
        "    )\n",
        "\n",
        "    return response_base.choices[0].message.content == response_changed.choices[0].message.content\n",
        "\n",
        "# Running Bias & Fairness Checks on Test Data\n",
        "for i, case in enumerate(test_data[:5]):\n",
        "    original_text = case[\"messages\"][1][\"content\"]\n",
        "    modified_text = original_text.replace(\"×”×©×•×¤×˜\", \"×”×©×•×¤×˜×ª\")  # Small gender swap for bias testing\n",
        "\n",
        "    bias_detected = check_bias(original_text, modified_text)\n",
        "\n",
        "    print(f\"Case {i+1}:\")\n",
        "    print(\"Original Judgment:\", original_text)\n",
        "    print(\"Modified Judgment:\", modified_text)\n",
        "    print(f\"Bias Detected (Counterfactual Fairness Check): {bias_detected}\")\n",
        "    print(\"-------------------------------------------------\")\n"
      ],
      "metadata": {
        "id": "xtz_uNBou0JI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "×‘4 ××ª×•×š 5 ××§×¨×™× ×œ× ×”×™×ª×” ×”×˜×™×” ××’×“×¨×™×ª."
      ],
      "metadata": {
        "id": "Gz0jnUCNzBpZ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "l7jmE17j8jXp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Function to check bias\n",
        "def check_bias(model_name, input_text, changed_feature):\n",
        "    response1 = client.chat.completions.create(\n",
        "        model=model_name,\n",
        "        messages=[{\"role\": \"system\", \"content\": \"××ª×” ××•××—×” ××©×¤×˜×™ ×œ× ×™×ª×•×— ×¤×¡×§×™ ×“×™×Ÿ\"},\n",
        "                  {\"role\": \"user\", \"content\": input_text}]\n",
        "    )\n",
        "\n",
        "    response2 = client.chat.completions.create(\n",
        "        model=model_name,\n",
        "        messages=[{\"role\": \"system\", \"content\": \"××ª×” ××•××—×” ××©×¤×˜×™ ×œ× ×™×ª×•×— ×¤×¡×§×™ ×“×™×Ÿ\"},\n",
        "                  {\"role\": \"user\", \"content\": changed_feature}]\n",
        "    )\n",
        "\n",
        "    return response1.choices[0].message.content == response2.choices[0].message.content\n",
        "\n",
        "input_text = \"×”×©×•×¤×˜ ×’×‘×¨×™××œ ×¤×¡×œ ××ª ×”×¢×¨×¢×•×¨.\"\n",
        "changed_text = \"×”×©×•×¤×˜×ª ×’×‘×¨×™××œ×” ×¤×¡×œ×” ××ª ×”×¢×¨×¢×•×¨.\"\n",
        "\n",
        "bias_detected = check_bias(latest_model, input_text, changed_text)\n",
        "print(f\"Bias Detected: {bias_detected}\")\n"
      ],
      "metadata": {
        "id": "zlnapDQNzM8i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ×‘×“×™×§×” ×× ×™×© Bias ×‘×˜×§×¡×˜×™× ×”××§×•×¨×™×™×"
      ],
      "metadata": {
        "id": "4whyfl-s3VZs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def check_bias_in_original_data(df):\n",
        "    male_terms = [\"×”×©×•×¤×˜\", \"×”×ª×•×‘×¢\", \"×”× ××©×\", \"×”×¢×•×ª×¨\"]\n",
        "    female_terms = [\"×”×©×•×¤×˜×ª\", \"×”×ª×•×‘×¢×ª\", \"×”× ××©××ª\", \"×”×¢×•×ª×¨×ª\"]\n",
        "\n",
        "    male_count = sum(df[\"×’×•×£ ×”××¡××š ×—×ª×•×š\"].str.count('|'.join(male_terms)))\n",
        "    female_count = sum(df[\"×’×•×£ ×”××¡××š ×—×ª×•×š\"].str.count('|'.join(female_terms)))\n",
        "\n",
        "    return {\"Male Count\": male_count, \"Female Count\": female_count, \"Bias Ratio\": male_count / (female_count + 1)}\n",
        "\n",
        "bias_in_data = check_bias_in_original_data(df)\n",
        "print(\"Bias in Original Data:\", bias_in_data)\n"
      ],
      "metadata": {
        "id": "vV1cHqHP3TOj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "×™×© ×”×˜×™×™×” ×‘× ×ª×•× ×™ ×”××§×•×¨.\n",
        "1. Data Augmentation\n",
        "2. UnderSamling\n",
        "3. Regulariation"
      ],
      "metadata": {
        "id": "pICzSzDu8F0h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ×”×× ×”××•×“×œ ××—××™×¨ ××ª ×”×”×˜×™×” ×”×§×™×™××ª"
      ],
      "metadata": {
        "id": "rCuMwzHU3d0e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def check_bias_in_model(model_name, input_text_male, input_text_female):\n",
        "    response_male = client.chat.completions.create(\n",
        "        model=model_name,\n",
        "        messages=[{\"role\": \"system\", \"content\": \"×¡×›× ××ª ×¤×¡×§ ×”×“×™×Ÿ ×‘×§×¦×¨×”.\"},\n",
        "                  {\"role\": \"user\", \"content\": input_text_male}]\n",
        "    ).choices[0].message.content\n",
        "\n",
        "    response_female = client.chat.completions.create(\n",
        "        model=model_name,\n",
        "        messages=[{\"role\": \"system\", \"content\": \"×¡×›× ××ª ×¤×¡×§ ×”×“×™×Ÿ ×‘×§×¦×¨×”.\"},\n",
        "                  {\"role\": \"user\", \"content\": input_text_female}]\n",
        "    ).choices[0].message.content\n",
        "\n",
        "    return {\"Male Output\": response_male, \"Female Output\": response_female}\n",
        "\n",
        "bias_in_model = check_bias_in_model(latest_model, input_text, changed_text)\n",
        "print(\"Bias in Model:\", bias_in_model)\n"
      ],
      "metadata": {
        "id": "-1CPmfqk05Br"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "××¡×§× ×” -\n",
        "\n",
        "××™×Ÿ ×”×˜×™×” ××’×“×¨×™×ª ××‘×—×™× ×ª ××•× ×—×™× ×›×œ×œ×™×™× (×”×©×•×¤×˜ - ×”×©×•×¤×˜×ª)\n",
        "\n",
        "××‘×œ - ×™×© ×”×©×¤×¢×” ×©×œ ×©××•×ª ×¡×¤×¦×™×¤×™×™× ××” ×©××¨××– ×¢×œ BIAS ×‘× ×ª×•× ×™× ×”××§×•×¨×™×™×.\n"
      ],
      "metadata": {
        "id": "lzTU1goY9uGW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "-KFwRZTO9-B2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### FactScore\n",
        "××“×“ ×œ×©×™××•×¨ ××©××¢×•×ª ××©×¤×˜×™×ª"
      ],
      "metadata": {
        "id": "XOE5hiVp05cE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_factscore_smart(model_name, original_text, generated_summary):\n",
        "    response = client.chat.completions.create(\n",
        "        model=model_name,\n",
        "        messages=[{\"role\": \"system\", \"content\": \"××ª×” ××•××—×” ××©×¤×˜×™. ×”×× ×”×¡×™×›×•× ×”×‘× ×ª×•×× ×œ×”×—×œ×˜×ª ×¤×¡×§ ×”×“×™×Ÿ? ×”×ª×™×™×—×¡ ×œ××©××¢×•×ª ×”××©×¤×˜×™×ª ×•×œ× ×¨×§ ×œ× ×™×¡×•×— ××™×œ×•×œ×™.\"},\n",
        "                  {\"role\": \"user\", \"content\": f\"×˜×§×¡×˜ ××§×•×¨×™: {original_text}\\n×¡×™×›×•×: {generated_summary}\\n×”×× ×”×¡×™×›×•× × ×××Ÿ ×œ××©××¢×•×ª ×©×œ ×¤×¡×§ ×”×“×™×Ÿ?\"}]\n",
        "    )\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "factscore_result = evaluate_factscore_smart(latest_model, original_text, generated_summary)\n",
        "print(f\"FactScore Evaluation (Smart): {factscore_result}\")\n"
      ],
      "metadata": {
        "id": "giUhDlvN09aT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "original_text"
      ],
      "metadata": {
        "id": "CeoBOONa4FJy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generated_summary"
      ],
      "metadata": {
        "id": "1IrXohx74IVG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "×ª×•×¦××” - ×”××•×“×œ ××©××¨ ××ª ×”××©××¢×•×ª ×”××©×¤×˜×™×ª ×©×œ ×”×”×—×œ×˜×” ×”××§×•×¨×™×ª ×•× ×××Ÿ ×œ××§×•×¨\n",
        "\n",
        "×©×™×¤×•×¨×™× ×œ×‘×“×™×§×•×ª\n",
        "1.   Edge cases\n",
        "\n"
      ],
      "metadata": {
        "id": "cd__qsKG7dOm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Attributable Generation"
      ],
      "metadata": {
        "id": "PrSerzS71H8A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "×‘×“×™×§×ª ×‘×¢×™×™×ª Hallucination"
      ],
      "metadata": {
        "id": "XN2klCnj7vf2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def check_attributable_generation_smart(model_name, original_text, generated_summary):\n",
        "    response = client.chat.completions.create(\n",
        "        model=model_name,\n",
        "        messages=[{\"role\": \"system\", \"content\": \"×”×× ×”×¡×™×›×•× ×”×‘× ××ª×‘×¡×¡ ×¢×œ ×”×—×œ×˜×•×ª ××©×¤×˜×™×•×ª ×§×•×“××•×ª, ××• ×©×”×•× ××›×™×œ ××™×“×¢ ××•××¦× ×©×œ× × ×ª××š ×‘×˜×§×¡×˜?\"},\n",
        "                  {\"role\": \"user\", \"content\": f\"×˜×§×¡×˜ ××§×•×¨×™: {original_text}\\n×¡×™×›×•×: {generated_summary}\\n×”×× ×”×¡×™×›×•× ××ª×‘×¡×¡ ×¢×œ ××™×“×¢ ××©×¤×˜×™ ×§×™×™×?\"}]\n",
        "    )\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "attribution_score = check_attributable_generation_smart(latest_model, original_text, generated_summary)\n",
        "print(f\"Attributable Generation Score (Smart): {attribution_score}\")\n"
      ],
      "metadata": {
        "id": "iCGcg2G81FVM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "5wlY7xo471vR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "KSgLnZfjzHLV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Promt engineering vs Fine tuning"
      ],
      "metadata": {
        "id": "1g7Slv5uvaup"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Function for Prompt Engineering Approach\n",
        "def prompt_engineering_example(query):\n",
        "    engineered_prompt = f\"××ª×” ××•××—×” ××©×¤×˜×™. ×¡×›× ××ª ×¤×¡×§ ×”×“×™×Ÿ ×”×‘× ×‘×§×¦×¨×”:\\n\\n{query}\"\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo-0125\",\n",
        "        messages=[{\"role\": \"user\", \"content\": engineered_prompt}]\n",
        "    )\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "# Function for Fine-Tuning Approach\n",
        "def fine_tuning_example(query):\n",
        "    response = client.chat.completions.create(\n",
        "        model= latest_model,\n",
        "        messages=[{\"role\": \"user\", \"content\": query}]\n",
        "    )\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "# Running the test on real cases\n",
        "for i, case in enumerate(test_data[:5]):\n",
        "    original_text = case[\"messages\"][1][\"content\"]\n",
        "\n",
        "    prompt_result = prompt_engineering_example(original_text)\n",
        "    fine_tuned_result = fine_tuning_example(original_text)\n",
        "\n",
        "    print(f\"Case {i+1}:\")\n",
        "    print(\"Original Judgment:\", original_text)\n",
        "    print(\"\\nğŸ“Œ Prompt Engineering Result:\", prompt_result)\n",
        "    print(\"\\nğŸ“Œ Fine-Tuning Result:\", fine_tuned_result)\n",
        "    print(\"-------------------------------------------------\")\n"
      ],
      "metadata": {
        "id": "9FQ2gbaJvhXM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Compare models"
      ],
      "metadata": {
        "id": "DjKF2l4C7n6J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil"
      ],
      "metadata": {
        "id": "F-B6-wfaGJts"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/api_key.txt\", \"r\") as file:\n",
        "    api_key = file.read().strip()\n",
        "\n",
        "client = openai.OpenAI(api_key=api_key)\n",
        "\n",
        "train_file = client.files.create(\n",
        "    file=open(\"train.jsonl\", \"rb\"),\n",
        "    purpose=\"fine-tune\"\n",
        ")\n",
        "\n",
        "# print(\"Train File ID:\", train_file.id)"
      ],
      "metadata": {
        "id": "B_3rtPbxB6HH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def generate_summary_gpt3(case_text):\n",
        "    response = client.chat.completions.create(\n",
        "        model=lates_model,\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"××ª×” ×¢×•×–×¨ ××©×¤×˜×™ ×”××¡×›× ×¤×¡×§×™ ×“×™×Ÿ.\"},\n",
        "            {\"role\": \"user\", \"content\": case_text}\n",
        "        ]\n",
        "    )\n",
        "    return response.choices[0].message.content\n",
        "\n"
      ],
      "metadata": {
        "id": "VkQN9Vr38TEL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_summary_llama2(case_text):\n",
        "    prompt = (\n",
        "        f\"{case_text}\\n\\n\"\n",
        "        \"### Task: Summarize the court ruling in one sentence.\\n\"\n",
        "        \"Summary:\"\n",
        "    )\n",
        "    input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(\"cuda\")\n",
        "    output = model.generate(input_ids, max_new_tokens=50)\n",
        "    return tokenizer.decode(output[0], skip_special_tokens=True).strip()\n"
      ],
      "metadata": {
        "id": "njGD9Try9TVd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "from rouge import Rouge\n",
        "\n",
        "# ğŸ“Œ ×¤×•× ×§×¦×™×” ×œ×”×©×•×•××ª ×‘×™×¦×•×¢×™× ×‘×™×Ÿ ×”××•×“×œ×™×\n",
        "def compare_models(original_text, human_summary):\n",
        "    gpt_summary = generate_summary_gpt3(original_text)  #  GPT-3.5\n",
        "    llama_summary = generate_summary_llama2(original_text)  #  Llama 2\n",
        "\n",
        "    bleu_gpt = sentence_bleu([human_summary.split()], gpt_summary.split())\n",
        "    bleu_llama = sentence_bleu([human_summary.split()], llama_summary.split())\n",
        "\n",
        "    rouge = Rouge()\n",
        "    rouge_gpt = rouge.get_scores(gpt_summary, human_summary)[0][\"rouge-l\"][\"f\"]\n",
        "    rouge_llama = rouge.get_scores(llama_summary, human_summary)[0][\"rouge-l\"][\"f\"]\n",
        "\n",
        "    print(f\"ğŸ“Œ BLEU GPT-3.5: {bleu_gpt:.4f}, BLEU Llama-2: {bleu_llama:.4f}\")\n",
        "    print(f\"ğŸ“Œ ROUGE GPT-3.5: {rouge_gpt:.4f}, ROUGE Llama-2: {rouge_llama:.4f}\")\n",
        "\n",
        "    return gpt_summary, llama_summary\n",
        "\n",
        "# ğŸ“Œ ×”×¨×¦×ª ×”×©×•×•××” ×œ×“×•×’××”\n",
        "original_case = dataset[\"valid\"][0][\"messages\"][1][\"content\"]\n",
        "human_summary = dataset[\"valid\"][0][\"messages\"][2][\"content\"]\n",
        "\n",
        "gpt_output, llama_output = compare_models(original_case, human_summary)\n",
        "\n",
        "print( gpt_output)\n",
        "print(llama_output)\n"
      ],
      "metadata": {
        "id": "LcYa9cSaCXXn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}