{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "name": "7_BOTH_MODELES_PREDICTIONS_add_CONTRYSIDE_columns.ipynb",
      "authorship_tag": "ABX9TyPkiE4aA5QySfhEERtKYeA3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/noambassat/SupremeCourtClassifier/blob/main/7_BOTH_MODELES_PREDICTIONS_add_CONTRYSIDE_columns.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BJg6S23X0nBC"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from pandas.api.types import CategoricalDtype\n",
        "import ast\n",
        "import joblib\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "full_ra_rap = pd.read_excel(\"full_ra_rap.xlsx\")"
      ],
      "metadata": {
        "id": "8UCe9a_Dnmy6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full_rap = full_ra_rap[full_ra_rap[\"סוג הליך\"]=='רע\"פ']\n",
        "# בדיקה אם בעמודת \"גוף המסמך\" קיימת המילה \"רע\"פ\"\n",
        "full_rap = full_rap[full_rap[\"גוף המסמך\"].str.contains('רע\"פ', na=False)]"
      ],
      "metadata": {
        "id": "0TkZXZzfzgc5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full_rap"
      ],
      "metadata": {
        "id": "cqjxrIJ814Oq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full_rap.shape"
      ],
      "metadata": {
        "id": "HKyKyb6v1o4r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full_rap[[\"גוף המסמך\"]].dropna(how='any', ignore_index=True,inplace=True)\n",
        "full_rap[[\"מספר הליך\",\"שם הליך\"]].dropna(how='all', ignore_index=True,inplace=True)\n",
        "full_rap[[\"מספר הליך\",\"שם הליך\"]].drop_duplicates(inplace=True, ignore_index=True)"
      ],
      "metadata": {
        "id": "yyhCbzCE18jj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# פונקציה להמרת טקסט שמופיע כרשימה למחרוזת רגילה\n",
        "def convert_list_to_string(text):\n",
        "    if isinstance(text, str) and text.startswith(\"[\") and text.endswith(\"]\"):\n",
        "        try:\n",
        "            # מנסה להמיר את התוכן בתוך הסוגריים לרשימה אמיתית\n",
        "            text_list = ast.literal_eval(text)\n",
        "            # איחוד המחרוזות לרצף טקסט אחד\n",
        "            return ' '.join(text_list)\n",
        "        except (ValueError, SyntaxError):\n",
        "            return text\n",
        "    return text\n",
        "\n",
        "# פונקציה לניקוי התווים המיותרים\n",
        "def clean_text(text):\n",
        "    if isinstance(text, list):\n",
        "        text = ' '.join(text)  # הפיכת רשימה למחרוזת\n",
        "    elif isinstance(text, str):\n",
        "        # הסרת תווי רווח מיותרים ותווים מיוחדים\n",
        "        text = re.sub(r'\\n+', ' ', text)  # הסרת שורות חדשות מרובות\n",
        "        text = re.sub(r'\\\\n', '', text)   # הסרת תווי newline \\n מהטקסט\n",
        "        text = re.sub(r'\\\\xa0', ' ', text)  # הסרת תווי \\xa0 מהטקסט\n",
        "        text = re.sub(r'\\s+', ' ', text)  # הסרת רווחים מרובים\n",
        "        return text.strip()\n",
        "    return text\n",
        "\n",
        "# הדפסת שורות לא קריאות לפני המרה\n",
        "print(\"שורות לא קריאות לפני המרה:\")\n",
        "print(full_rap[\"גוף המסמך\"].head())\n",
        "\n",
        "# המרה של הטקסטים הלא קריאים לטקסטים קריאים ושמירה על הדאטה המקורי\n",
        "full_rap[\"גוף המסמך\"] = full_rap[\"גוף המסמך\"].apply(clean_text)\n",
        "\n",
        "print(\"\\nשורות לאחר המרה:\")\n",
        "print(full_rap[\"גוף המסמך\"].head())\n",
        "\n",
        "file_path = 'full_rap_df_cleaned.csv'\n",
        "full_rap.to_csv(file_path, index=False, encoding='utf-8')\n",
        "\n",
        "# print(f\"הקובץ נשמר בהצלחה בנתיב: {file_path}\")\n"
      ],
      "metadata": {
        "id": "P4-tNosi2Eoc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# בדיקה אם הערכים השתנו\n",
        "changed_rows = full_rap[\"גוף המסמך\"] != full_rap[\"גוף המסמך\"].apply(clean_text)\n",
        "print(f\"מספר שורות ששונו: {changed_rows.sum()}\")\n",
        "print(\"שורות ששונו:\")\n",
        "print(full_rap.loc[changed_rows, \"גוף המסמך\"].head())\n"
      ],
      "metadata": {
        "id": "zGZpVinogEnG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full_rap"
      ],
      "metadata": {
        "id": "PPlpIGQQ2bEy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# הגדרת פונקציה לעיצוב טקסט\n",
        "def format_text(text, line_length=80):\n",
        "    \"\"\"\n",
        "    פורמט טקסט כך שיהיה נוח לקריאה עם שורות שאורכן מוגבל.\n",
        "    \"\"\"\n",
        "    import textwrap\n",
        "    return \"\\n\".join(textwrap.wrap(text, width=line_length))\n"
      ],
      "metadata": {
        "id": "rfU7YyxL0qDg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ביטויים לבדיקה\n",
        "keywords = [\"העותק כפוף לשינויי עריכה וניסוח\", \"העתק מתאים\", 'ניתנההיום', 'ניתןהיום', 'ניתן היום', 'ניתנה היום',\n",
        "            \"העתקמתאים\", \"מזכיר ראשי\", \"supreme.court.gov.il\", \"מרכז מידע\", \"מרכזמידע\"]\n",
        "\n",
        "# בדיקה אילו שורות מכילות אחד מהביטויים\n",
        "rows_with_keyword = full_rap[\"גוף המסמך\"].apply(\n",
        "    lambda x: any(keyword in x for keyword in keywords) if isinstance(x, str) else False\n",
        ")\n",
        "\n",
        "# סינון שורות שלא מכילות את הביטוי\n",
        "filtered_data = full_rap[rows_with_keyword]\n",
        "\n",
        "# הדפסת מספר השורות שנמחקו\n",
        "num_removed = len(full_rap) - len(filtered_data)  # **שונה לחישוב מדויק**\n",
        "print(f\"\\nמספר השורות שנמחקו: {num_removed}\")\n",
        "\n",
        "# **שינוי לצורך סעיף 6**: בדיקה אם נותרו ערכים חסרים בעמודת \"גוף המסמך\"\n",
        "missing_values_count = filtered_data[\"גוף המסמך\"].isna().sum()\n",
        "if missing_values_count > 0:\n",
        "    print(f\"\\nנותרו {missing_values_count} ערכים חסרים בעמודת 'גוף המסמך' לאחר סינון.\")\n",
        "else:\n",
        "    print(\"\\nאין ערכים חסרים בעמודת 'גוף המסמך' לאחר סינון.\")\n",
        "\n",
        "# שמירת הנתונים המסוננים לקובץ חדש\n",
        "filtered_data.to_csv(\"full_rap_df_cleaned.csv\", index=False, encoding='utf-8')\n",
        "print(\"\\nהנתונים המסוננים נשמרו לקובץ: 'new_filtered_data.csv'\")\n",
        "\n",
        "\n",
        "full_rap = filtered_data.copy()  # **שונה להעתקה בטוחה**\n"
      ],
      "metadata": {
        "id": "hHv428bA0qF8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full_rap"
      ],
      "metadata": {
        "id": "JhwsRNES0qIQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for col in full_rap.columns:\n",
        "  print(col)"
      ],
      "metadata": {
        "id": "Dnpp67hB08tY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sides = full_rap[[\n",
        "\"צד א'\",\n",
        "\"צד ב'\"\n",
        "]]"
      ],
      "metadata": {
        "id": "2fjkL6dr12hL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "values = [val for value in sides.values for val in value]\n",
        "values"
      ],
      "metadata": {
        "id": "cbgBE4ARKFuK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clean_values = set()\n",
        "for val in values:\n",
        "    val_str = str(val)  # המרה למחרוזת\n",
        "    cleaned_val = re.sub(r\"[\\[\\]'\\\\n]\", \"\", val_str).strip()\n",
        "    clean_values.add(cleaned_val)"
      ],
      "metadata": {
        "id": "2qZwFusBLqId"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clean_values"
      ],
      "metadata": {
        "id": "puE5QLmQMVgk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def check_sub(value,subs):\n",
        "  for sub in subs:\n",
        "    if(value.find(sub)!=-1):\n",
        "      return 1\n",
        "  return 0"
      ],
      "metadata": {
        "id": "ewhOZUMFMdJG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "private_sides = set()\n",
        "public_sides = set()\n",
        "for value in clean_values:\n",
        "  if(check_sub(value,[\"רשות מקרקעי ישראל\",\"מדינת \",\"מועצה \",\"שירות ה\",\"היחידה הארצי\",\"לאכיפת \",\"הרשות ל\",\"המשרד ל\",'יועמ\"ש',\"המשפטי לממשלה\",\"מנהל מקרקעי\",\"פרקליטות\",\"שירות בתי הסוהר\",'שב\"ס',\"מינהל מקרקעי\",\"עירית \",\"רשויות\",\"איגוד ערים\",\"עיריית \",\"מדינת ישראל\",\"משרד ה\",\"רשות ה\",\"אלוף \",'יו\"ר',\"יושב ראש\",\"מדינת ישראל\",\"ראש עיריית\",\"ועדה\",\"צבא\",\"מפקד\",\"פיקוד\",\"משטרת\"])==0):\n",
        "    private_sides.add(value)\n",
        "  else:\n",
        "    public_sides.add(value)"
      ],
      "metadata": {
        "id": "yKgex7WoMzO7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for side in private_sides:\n",
        "  print(side)"
      ],
      "metadata": {
        "id": "HXhVK_imM-lF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for side in public_sides:\n",
        "  print(side)"
      ],
      "metadata": {
        "id": "8mhcru_onwJf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sides_A = full_rap[[\n",
        "\"צד א'\"\n",
        "]]\n",
        "\n",
        "values_A = [val for value in sides_A.values for val in value]\n",
        "values_A"
      ],
      "metadata": {
        "id": "LSBXxD4RbMxc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "08XJzGEjpEsb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def check_contry_side(value):\n",
        "    # רשימת מילות מפתח\n",
        "    subs = [\n",
        "        \"רשות מקרקעי ישראל\", \"מדינת \", \"מועצה \", \"שירות ה\", \"היחידה הארצי\", \"לאכיפת \", \"הרשות ל\",\n",
        "        \"המשרד ל\", 'יועמ\"ש', \"המשפטי לממשלה\", \"מנהל מקרקעי\", \"פרקליטות\", \"שירות בתי הסוהר\", 'שב\"ס',\n",
        "        \"מינהל מקרקעי\", \"עירית \", \"רשויות\", \"איגוד ערים\", \"עיריית \", \"מדינת ישראל\", \"משרד ה\", \"מקרקעי ישראל\",\n",
        "        \"רשות ה\", \"אלוף \", 'יו\"ר', \"יושב ראש\", \"ראש עיריית\", \"ועדה\", \"צבא\", \"מפקד\", \"פיקוד\", \"משטרת\"\n",
        "    ]\n",
        "\n",
        "    # ניקוי רווחים והפיכת המחרוזת לאותיות קטנות\n",
        "    try:\n",
        "      value = value.strip()\n",
        "\n",
        "    except AttributeError:\n",
        "      return 0\n",
        "\n",
        "    # בדיקה אם אחת המחרוזות קיימת ב-value\n",
        "    if any(sub in value for sub in subs):\n",
        "        return 1\n",
        "    print(value)\n",
        "\n",
        "    return 0"
      ],
      "metadata": {
        "id": "TX02-aQbpF_v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "check_none = full_rap[full_rap[\"צד א'\"].isna()]\n",
        "check_none.loc[:,\"צד ב'\"]"
      ],
      "metadata": {
        "id": "2JQLsnYssaaR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full_rap[full_rap[\"צד א'\"].isna() & full_rap[\"צד ב'\"].isna()].shape[0]"
      ],
      "metadata": {
        "id": "r3AB0kzLr3wi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full_rap.dropna(subset=[\"צד א'\",\"צד ב'\"],how='all',inplace=True)"
      ],
      "metadata": {
        "id": "FiUfegLur3BX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full_rap[\"מדינת ישראל בצד א'\"] = full_rap[\"צד א'\"].apply(lambda x: check_contry_side(x))"
      ],
      "metadata": {
        "id": "D8Hua7gbbM0B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nsGZxISmrzIo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "R1Xad7N2tbI-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "unmkHrmVtbLa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XSYMnCk6tbON"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IYqdml6Vd5DL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bEK6yfoDd5FY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qSEetgvJd5AM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5jzNw2K_d5Hz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1VYCZeAOeYdJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "veTv9POXem9V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create checked data - to remove from predictions"
      ],
      "metadata": {
        "id": "LsxlzvTd0-Rp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dca = pd.read_csv(\"dca_for_classifier.csv\")"
      ],
      "metadata": {
        "id": "K-KGNMdNestT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ignore_df_1 = pd.read_excel(\"full_data_BOTH_models_with_predictions_V.xlsx\")\n",
        "ignore_df_1.dropna(subset=['בקשה לרשות ערעור התקבלה?'],inplace=True)\n",
        "ignore_df_2 = pd.read_excel(\"2_full_data_with_predictions V2.xlsx\")\n",
        "ignore_df_2.dropna(subset=['בקשה לרשות ערעור התקבלה?'],inplace=True)\n",
        "ignore_df_3 = pd.read_excel(\"full_data_with_predictions-VETTING.xlsx\")\n",
        "ignore_df_3.dropna(subset=['בקשה לרשות ערעור התקבלה?'],inplace=True)\n",
        "ignore_df = pd.concat([ignore_df_1,ignore_df_2,ignore_df_3,dca])\n",
        "ignore_df.dropna(subset=['בקשה לרשות ערעור התקבלה?'],inplace=True)\n",
        "ignore_df.drop_duplicates(subset=['מספר הליך'],keep='first',inplace=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "Li78RR0CcKeO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ignore_df.shape"
      ],
      "metadata": {
        "id": "yMx-PtivyOHU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ignore_df['רע\"פ בקשה אחרת או דלמטה מיוחד'].value_counts()"
      ],
      "metadata": {
        "id": "ijtShKjIxjYm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ignore_df[~ignore_df['רע\"פ בקשה אחרת או דלמטה מיוחד'].isna()].shape"
      ],
      "metadata": {
        "id": "JrUVl98PzZGy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ignore_df[(ignore_df['רע\"פ בקשה אחרת או דלמטה מיוחד'] != 'בקשה אחרת') & (ignore_df['רע\"פ בקשה אחרת או דלמטה מיוחד'] != 'דלמטה מיוחד')].shape"
      ],
      "metadata": {
        "id": "OCcWXk38y1Pc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ignore_df[~ignore_df['רע\"פ בקשה אחרת או דלמטה מיוחד'].isna()].shape"
      ],
      "metadata": {
        "id": "zz_Vf-8azHLk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "delete_from_main_df = ignore_df[~ignore_df['רע\"פ בקשה אחרת או דלמטה מיוחד'].isna()]\n",
        "delete_from_main_df.shape"
      ],
      "metadata": {
        "id": "NMwnGVtnzA5e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ignore_df[(ignore_df['בקשה לרשות ערעור התקבלה?']== 'אחר')].shape"
      ],
      "metadata": {
        "id": "OoBGj4mHyJ9n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ignore_df.to_csv(\"allready_checked_data_with_dca.csv\", index=False, encoding='utf-8')"
      ],
      "metadata": {
        "id": "ow_t4Sk913Gy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "delete_from_main_df = pd.concat([delete_from_main_df,ignore_df[(ignore_df['בקשה לרשות ערעור התקבלה?'] == 'אחר')]])"
      ],
      "metadata": {
        "id": "ISvM0lMozhuA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "delete_from_main_df.shape"
      ],
      "metadata": {
        "id": "AvsMQKDizooK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "delete_from_main_df.drop_duplicates(subset=['מספר הליך'],keep='first',inplace=True)"
      ],
      "metadata": {
        "id": "kslMPDWf0kQ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "delete_from_main_df.shape"
      ],
      "metadata": {
        "id": "hUBJjodp1PKL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full_rap.shape"
      ],
      "metadata": {
        "id": "iR9Bov-m08oY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full_rap = full_rap[~full_rap[\"מספר הליך\"].isin(delete_from_main_df[\"מספר הליך\"])]"
      ],
      "metadata": {
        "id": "WaBR91OJ0zH_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qb_nxpPW1acn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full_rap"
      ],
      "metadata": {
        "id": "RdKJgiXU1l9L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cut doc's body for classifiers"
      ],
      "metadata": {
        "id": "zhwbEDCy2cVZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# פונקציה לחיתוך הטקסט בהתאם לכללים\n",
        "def trim_text(text,min_length=500,last_sen=30):\n",
        "\n",
        "\n",
        "    # שמירת אורך מקורי לאבחון\n",
        "    original_length = len(text)\n",
        "\n",
        "    # הסרת מספר תווים מסוף הטקסט\n",
        "    text = text[:-last_sen]\n",
        "\n",
        "    # חיתוך ל-min_length האחרונים אם הטקסט ארוך יותר מהמינימום\n",
        "    if len(text) > min_length:\n",
        "        text = text[-min_length:]\n",
        "\n",
        "    # הדפסת פידבק רק אם הטקסט עבר שינוי\n",
        "    # if len(text) != original_length:\n",
        "    #     print(f\"Trimmed Text (Original Length: {original_length}, Trimmed Length: {len(text)}):\")\n",
        "    #     formatted_text = \"\\n\".join([text[i:i+80] for i in range(0, len(text), 80)])\n",
        "    #     print(formatted_text)\n",
        "    #     print(\"##*******************************************************####\")\n",
        "    return text\n"
      ],
      "metadata": {
        "id": "L6mTLybi1mCj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# חיתוך הטקסטים בעמודת \"גוף המסמך\"\n",
        "full_rap[\"גוף המסמך חתוך\"] = full_rap[\"גוף המסמך\"].apply(trim_text)\n",
        "full_rap[\"גוף המסמך חתוך למסווג השני\"] = full_rap[\"גוף המסמך\"].apply(lambda x: trim_text(x, 550, 80))\n",
        "# שמירת האינדקס המקורי\n",
        "full_rap.reset_index(inplace=True, drop=False)\n"
      ],
      "metadata": {
        "id": "P_u9U5Ux3pjx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full_rap.to_excel(\"full_rap_df_cleaned.xlsx\", index=False, encoding='utf-8')"
      ],
      "metadata": {
        "id": "ZbNSl9lk1mFP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Embeddings"
      ],
      "metadata": {
        "id": "buI0ArrY4kCi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"dean-ai/sentence_transformer_Legal-heBERT\")\n",
        "model = AutoModel.from_pretrained(\"dean-ai/sentence_transformer_Legal-heBERT\")"
      ],
      "metadata": {
        "id": "6ZgQIkyD4mG4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_embeddings(text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "    outputs = model(**inputs)\n",
        "    embeddings = outputs.last_hidden_state.mean(dim=1).detach().numpy()\n",
        "    return embeddings[0]"
      ],
      "metadata": {
        "id": "rsX7IPEH4m_s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# חישוב ושמירת אימבדינגים לעמודה הראשונה\n",
        "\n",
        "print(\"מתחילים לחשב אימבדינגים על גוף המסמך החתוך...\")\n",
        "full_rap[\"גוף המסמך חתוך - embeddings\"] = full_rap[\"גוף המסמך חתוך\"].apply(lambda text: get_embeddings(text))\n",
        "print(\"אימבדינגים חושבו בהצלחה!\")\n"
      ],
      "metadata": {
        "id": "SgDr3lff4q7Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "plA3F5Sm5_BO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "F31qdyP25_Do"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# First classifier predictions"
      ],
      "metadata": {
        "id": "qP7mmNr86De_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def model_prediction(data, name,treshold, classifier, embeddings):\n",
        "\n",
        "  predicted_probabilities = classifier.predict_proba(embeddings)[:, 1]\n",
        "\n",
        "  data[f\"{name}_predicted_probability\"] = predicted_probabilities\n",
        "\n",
        "  data[f\"{name}_original_prediction\"] = classifier.predict(embeddings)\n",
        "\n",
        "  data[f\"{name}_treshold_prediction\"] = (predicted_probabilities > treshold).astype(int)\n",
        "\n",
        "\n",
        "\n",
        "  # PRINTS\n",
        "  class_distribution = data[f\"{name}_original_prediction\"].value_counts()\n",
        "  print(\"\\nכמות Class 0 ו-Class 1 (לפי המודל המקורי):\")\n",
        "  print(class_distribution)\n",
        "\n",
        "  # בדיקת התפלגות נורמלית\n",
        "  normalized_distribution = data[f\"{name}_original_prediction\"].value_counts(normalize=True)\n",
        "  print(\"\\nהתפלגות נורמלית של Class 0 ו-Class 1 (לפי המודל המקורי):\")\n",
        "  print(normalized_distribution)\n",
        "\n",
        "\n",
        "  # בדיקת התפלגות התחזיות עם הסף החדש\n",
        "  adjusted_class_distribution = data[f\"{name}_treshold_prediction\"].value_counts()\n",
        "  print(\"\\nכמות Class 0 ו-Class 1 (לפי הסף המותאם):\")\n",
        "  print(adjusted_class_distribution)\n",
        "\n",
        "  # בדיקת התפלגות נורמלית עם הסף החדש\n",
        "  adjusted_normalized_distribution = data[f\"{name}_treshold_prediction\"].value_counts(normalize=True)\n",
        "  print(\"\\nהתפלגות נורמלית של Class 0 ו-Class 1 (לפי הסף המותאם):\")\n",
        "  print(adjusted_normalized_distribution)\n",
        "\n",
        "  # שמירת הנתונים לקובץ Excel\n",
        "  output_file_adjusted = \"Full_RAAP_with_predictions.xlsx\"\n",
        "  data.to_excel(output_file_adjusted, index=False, engine=\"openpyxl\")"
      ],
      "metadata": {
        "id": "Hzxr2oT-6sFz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_prediction(full_rap,\"first_classifier\",0.67, joblib.load(\"3_first_classifier_model_Triple_trained.pkl\"), np.array(full_rap[\"גוף המסמך חתוך - embeddings\"].tolist()))"
      ],
      "metadata": {
        "id": "YsFnsRvC6KXF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MUDecLDC6Kai"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RBBOtFYR6Kdh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Second classifier predictions"
      ],
      "metadata": {
        "id": "bYQBP2kd6HAu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = full_rap[full_rap[\"first_classifier_treshold_prediction\"]==1].copy()"
      ],
      "metadata": {
        "id": "Z1GO6oALV9zJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# חישוב ושמירת אימבדינגים לעמודה השנייה\n",
        "print(\"מתחילים לחשב אימבדינגים על גוף המסמך החתוך השני...\")\n",
        "data[\"גוף המסמך חתוך למסווג השני - embeddings\"] = data[\"גוף המסמך חתוך למסווג השני\"].apply(lambda text: get_embeddings(text))\n",
        "print(\"אימבדינגים 2 חושבו בהצלחה!\")\n"
      ],
      "metadata": {
        "id": "Gv5ZGvddWW_o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_prediction(data, \"second_classifier\",0.9, joblib.load(\"second_classifier_model.pkl\"), np.array(data[\"גוף המסמך חתוך למסווג השני - embeddings\"] .tolist()))"
      ],
      "metadata": {
        "id": "BEFjZQCV9y-c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full_rap = pd.concat([data,full_rap])\n",
        "full_rap.drop_duplicates(subset = [\"מספר הליך\"],keep = 'first', inplace=True)\n"
      ],
      "metadata": {
        "id": "7nUxW-YpWOOV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# חיבור Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# הגדרת נתיב לשמירה בדרייב\n",
        "file_path = '/content/drive/My Drive/full_rap_df_cleaned.xlsx'\n",
        "\n",
        "# שמירת הקובץ\n",
        "full_rap.to_excel(file_path, index=False)\n",
        "\n",
        "print(f\"File saved successfully to {file_path}\")\n"
      ],
      "metadata": {
        "id": "RZyM-fIJddno"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Remove checked data from the prediction's sample!!!"
      ],
      "metadata": {
        "id": "pazQdALw1m2s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "full_rap.shape"
      ],
      "metadata": {
        "id": "y6TwlNr59_LW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "none_checked_raap = full_rap[~full_rap[\"מספר הליך\"].isin(ignore_df[\"מספר הליך\"])]"
      ],
      "metadata": {
        "id": "R0-Fsuia1mHN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "none_checked_raap.shape"
      ],
      "metadata": {
        "id": "YPEjRPhW-HS_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_df = none_checked_raap[[\"מספר תיק\", \"מספר הליך\",\"Year\",\"מדינת ישראל בצד א'\",\n",
        "    'גוף המסמך חתוך', 'גוף המסמך חתוך למסווג השני',\n",
        "       'גוף המסמך חתוך - embeddings',\n",
        "       'גוף המסמך חתוך למסווג השני - embeddings',\n",
        "       'first_classifier_predicted_probability',\n",
        "       'first_classifier_original_prediction',\n",
        "       'first_classifier_treshold_prediction',\n",
        "       'second_classifier_predicted_probability',\n",
        "       'second_classifier_original_prediction',\n",
        "       'second_classifier_treshold_prediction']\n",
        "]"
      ],
      "metadata": {
        "id": "CIRBnZqGL_sB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_df.shape"
      ],
      "metadata": {
        "id": "uTvpjx_kR_2g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract the set of case numbers in dca\n",
        "dca_cases = set(dca[\"מספר תיק\"])\n",
        "ignore_cases = set(ignore_df[\"מספר תיק\"])\n",
        "# Filter sample_df to exclude rows where 'מספר התיק' is in dca_cases\n",
        "filtered_sample_df = sample_df[~sample_df[\"מספר תיק\"].isin(dca_cases)]\n",
        "\n",
        "filtered_sample_df = filtered_sample_df[~filtered_sample_df[\"מספר הליך\"].isin(ignore_cases)]"
      ],
      "metadata": {
        "id": "0R9x4UzyRQba"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_df = filtered_sample_df.copy()\n",
        "sample_df.shape"
      ],
      "metadata": {
        "id": "mFzWOApWRgOm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_df = sample_df[sample_df[\"Year\"]>=2000]"
      ],
      "metadata": {
        "id": "rauCunrwUE2N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(sample_df[\"Year\"].unique())"
      ],
      "metadata": {
        "id": "NtWZPTj4OJ2a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def summarize_predictions_by_year(col):\n",
        "    # Group by Year and first_classifier_treshold_prediction, then count occurrences\n",
        "    summary = sample_df.groupby([\"Year\", col]).size().unstack(fill_value=0)\n",
        "    summary.columns = [\"Class 0\", \"Class 1\"]  # Rename columns for clarity\n",
        "    return summary\n"
      ],
      "metadata": {
        "id": "v2w0oGMFPT7G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Usage example:\n",
        "summary_df_1 = summarize_predictions_by_year(\"first_classifier_treshold_prediction\")\n",
        "summary_df_1\n"
      ],
      "metadata": {
        "id": "Pxeim13fPsSf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Usage example:\n",
        "summary_df_2 = summarize_predictions_by_year(\"second_classifier_treshold_prediction\")\n",
        "summary_df_2\n"
      ],
      "metadata": {
        "id": "WLQM_4YCPt6A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def balance_data_with_year_2000(data, prediction_column, year_column):\n",
        "    balanced_data = []\n",
        "    for year, group in data.groupby(year_column):\n",
        "        if year == 2000:\n",
        "            # מוסיפים את כל הנתונים של שנת 2000\n",
        "            balanced_data.append(group)\n",
        "        else:\n",
        "            # מאוזנים עבור שנים אחרות\n",
        "            ones = group[group[prediction_column] == 1]\n",
        "            zeros = group[group[prediction_column] == 0].sample(len(ones), random_state=42)\n",
        "            balanced_data.append(pd.concat([ones, zeros]))\n",
        "    # איחוד כל השנים למאגר אחד\n",
        "    return pd.concat(balanced_data)\n",
        "\n",
        "# שימוש בפונקציה\n",
        "balanced_sample_df = balance_data_with_year_2000(sample_df, \"first_classifier_treshold_prediction\", \"Year\")\n"
      ],
      "metadata": {
        "id": "BH3J5tPnjTAW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "balanced_sample_df"
      ],
      "metadata": {
        "id": "WE0FhcvkjXpj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "balanced_sample_df['בקשה לרשות ערעור התקבלה?'] = None\n",
        "balanced_sample_df['הערעור התקבל?'] = None\n",
        "balanced_sample_df['רע\"פ בקשה אחרת או דלמטה מיוחד'] = None"
      ],
      "metadata": {
        "id": "8xCHlMjLkbP0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XLI_mWAnk2lQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "balanced_sample_df.to_excel(\"final_sample_df.xlsx\", index=False)"
      ],
      "metadata": {
        "id": "q__K6pL1k13f"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}