{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "cell_execution_strategy": "setup",
      "authorship_tag": "ABX9TyMDATXTURaSKvh7V7EDPn+u",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/noambassat/SupremeCourtClassifier/blob/main/8_None_relevant_cases_classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vvVtg-CzCG2y"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoModel\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import joblib\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import cross_validate, cross_val_score, StratifiedKFold,train_test_split,cross_val_predict\n",
        "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score,make_scorer, accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "# from imblearn.under_sampling import RandomUnderSampler\n",
        "\n",
        "from google.colab import drive\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# התחברות ל-Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n"
      ],
      "metadata": {
        "id": "rUu4l0zkFPox"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "folder_id = \"בית המשפט - קבצים שנבדקו\"\n",
        "directory_path = f\"/content/drive/My Drive/{folder_id}\"\n",
        "\n",
        "if not os.path.exists(directory_path):\n",
        "    print(f\"Directory {directory_path} does not exist. Please check the folder path.\")\n",
        "else:\n",
        "    dataframes = []\n",
        "\n",
        "    for file_name in os.listdir(directory_path):\n",
        "        if file_name.endswith(\".xlsx\") or file_name.endswith(\".xls\"):\n",
        "            file_path = os.path.join(directory_path, file_name)\n",
        "            try:\n",
        "                df = pd.read_excel(file_path)\n",
        "                dataframes.append(df)\n",
        "            except Exception as e:\n",
        "                print(f\"Failed to read {file_name}: {e}\")\n",
        "\n",
        "    if dataframes:\n",
        "        combined_df = pd.concat(dataframes, ignore_index=True)\n",
        "        print(\"All Excel files have been concatenated successfully!\")\n",
        "\n",
        "        output_file = \"/content/drive/My Drive/combined_excel.xlsx\"  # עדכן את הנתיב לשמירת הקובץ\n",
        "        combined_df.to_excel(output_file, index=False)\n",
        "        print(f\"Combined file saved at: {output_file}\")\n",
        "    else:\n",
        "        print(\"No Excel files found or failed to read.\")\n"
      ],
      "metadata": {
        "id": "7-8rCVEjDjXf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combined_df"
      ],
      "metadata": {
        "id": "jY-WmHHJFL3S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = combined_df.dropna(subset = ['בקשה לרשות ערעור התקבלה?'])"
      ],
      "metadata": {
        "id": "aURDtSENFdyG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "id": "MXEadjvmFn6U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['רע\"פ בקשה אחרת או דלמטה מיוחד'].value_counts()\n"
      ],
      "metadata": {
        "id": "AHhMj1ASFwpD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data[(data['רע\"פ בקשה אחרת או דלמטה מיוחד'] == 'בקשה אחרת') | (data['רע\"פ בקשה אחרת או דלמטה מיוחד'] == 'דלמטה מיוחד')].shape[0]"
      ],
      "metadata": {
        "id": "H5vRI9G_F1J7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data[\"אחר\"] = data.apply(\n",
        "    lambda row: 1 if row[\"בקשה לרשות ערעור התקבלה?\"] == \"אחר\" or not pd.isna(row['רע\"פ בקשה אחרת או דלמטה מיוחד']) else 0, axis=1\n",
        ")"
      ],
      "metadata": {
        "id": "QqViVPoyHTdR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data[\"אחר\"].value_counts()"
      ],
      "metadata": {
        "id": "WtpvDEl4HWWs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.drop_duplicates(subset=[\"מספר הליך\"], inplace=True)"
      ],
      "metadata": {
        "id": "QpPYfxHMH3JO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data[\"אחר\"].value_counts()"
      ],
      "metadata": {
        "id": "AnaFPcepQHy-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Embedding"
      ],
      "metadata": {
        "id": "IvHSVOA_H3iw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"dean-ai/sentence_transformer_Legal-heBERT\")\n",
        "model = AutoModel.from_pretrained(\"dean-ai/sentence_transformer_Legal-heBERT\")"
      ],
      "metadata": {
        "id": "yEbeW64CHnRL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_embeddings(text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "    outputs = model(**inputs)\n",
        "    embeddings = outputs.last_hidden_state.mean(dim=1).detach().numpy()\n",
        "    return embeddings[0]"
      ],
      "metadata": {
        "id": "lm7q1AQLH5mh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# print(\"מתחילים לחשב אימבדינגים על גוף המסמך המלא...\")\n",
        "# data[\"גוף המסמך המלא - embeddings\"] = data[\"גוף המסמך\"].apply(lambda text: get_embeddings(text))\n",
        "# print(\"אימבדינגים 1 חושבו בהצלחה!\")\n",
        "\n",
        "\n",
        "print(\"מתחילים לחשב אימבדינגים על גוף המסמך החתוך...\")\n",
        "data[\"גוף המסמך חתוך - embeddings\"] = data[\"גוף המסמך חתוך\"].apply(lambda text: get_embeddings(text))\n",
        "print(\"אימבדינגים 2 חושבו בהצלחה!\")\n"
      ],
      "metadata": {
        "id": "LzJX5kYxIDVR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_file = \"/content/drive/My Drive/all_OTHER_cases_with_embeddings.xlsx\"\n",
        "data.to_excel(output_file, index=False)\n",
        "print(f\"Combined file saved at: {output_file}\")"
      ],
      "metadata": {
        "id": "Kt37YBK5IjZR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0SQikuDUI5s8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "36dzH4N7I5xl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Split and train classifier"
      ],
      "metadata": {
        "id": "Ik95ope4I6C-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "import joblib\n",
        "\n",
        "# הכנת הנתונים\n",
        "X = np.array(data[\"גוף המסמך חתוך - embeddings\"].tolist())  # הפיכת העמודה לרשימה\n",
        "y = data[\"אחר\"].values\n",
        "\n",
        "# שמירת אינדקסים מקוריים\n",
        "data = data.reset_index(drop=True)  # איפוס האינדקס של ה-DataFrame\n",
        "original_indices = data.index.values  # שמירת האינדקסים המקוריים\n",
        "\n",
        "# הוספת אינדקסים לנתונים\n",
        "indices = np.arange(len(X))\n",
        "X_with_indices = np.hstack([X, indices.reshape(-1, 1)])  # הוספת אינדקסים כעמודה אחרונה\n",
        "\n",
        "# ביצוע undersampling\n",
        "undersampler = RandomUnderSampler(sampling_strategy=0.9, random_state=42)\n",
        "X_resampled_with_indices, y_resampled = undersampler.fit_resample(X_with_indices, y)\n",
        "\n",
        "# הפרדת האינדקסים מסט האימון\n",
        "X_resampled = X_resampled_with_indices[:, :-1]  # כל העמודות פרט לעמודת האינדקסים\n",
        "indices_resampled = X_resampled_with_indices[:, -1].astype(int)  # עמודת האינדקסים\n",
        "\n",
        "# יצירת סט הבדיקה מהאינדקסים שלא נבחרו\n",
        "indices_test = np.setdiff1d(indices, indices_resampled)\n",
        "X_test = X[indices_test]\n",
        "y_test = y[indices_test]\n",
        "\n",
        "# הגדרת משקלות לסיווג לא מאוזן\n",
        "class_weights = {0: 1, 1: 1}\n",
        "\n",
        "# יצירת המודל של Logistic Regression\n",
        "classifier = LogisticRegression(class_weight=class_weights, random_state=42, max_iter=1000)\n",
        "\n",
        "# אימון המודל על ה-TRAIN SET\n",
        "classifier.fit(X_resampled, y_resampled)\n",
        "\n",
        "# חיזוי על ה-TRAIN SET\n",
        "y_train_pred = classifier.predict(X_resampled)\n",
        "y_train_pred_prob = classifier.predict_proba(X_resampled)[:, 1]\n",
        "\n",
        "# חיזוי על ה-TEST SET\n",
        "y_test_pred = classifier.predict(X_test)\n",
        "y_test_pred_prob = classifier.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# שמירת ההסתברויות והחיזוי בדאטה המקורי עבור כל הנתונים\n",
        "data[\"Prediction\"] = np.nan\n",
        "data[\"Prediction_Probability\"] = np.nan\n",
        "\n",
        "# עדכון סט האימון\n",
        "data.loc[indices_resampled, \"Prediction\"] = y_train_pred\n",
        "data.loc[indices_resampled, \"Prediction_Probability\"] = y_train_pred_prob\n",
        "\n",
        "# עדכון סט הבדיקה\n",
        "data.loc[indices_test, \"Prediction\"] = y_test_pred\n",
        "data.loc[indices_test, \"Prediction_Probability\"] = y_test_pred_prob\n",
        "\n",
        "# חישוב מטריצות בלבול\n",
        "conf_matrix_train = confusion_matrix(y_resampled, y_train_pred)\n",
        "conf_matrix_test = confusion_matrix(y_test, y_test_pred)\n",
        "\n",
        "# דוח ביצועים מלאים\n",
        "print(\"\\nTrain Set Results:\")\n",
        "print(f\"Confusion Matrix (Train):\\n{conf_matrix_train}\")\n",
        "print(\"\\nClassification Report (Train):\")\n",
        "print(classification_report(y_resampled, y_train_pred, target_names=[\"Class 0\", \"Class 1\"]))\n",
        "\n",
        "print(\"\\nTest Set Results:\")\n",
        "print(f\"Confusion Matrix (Test):\\n{conf_matrix_test}\")\n",
        "print(\"\\nClassification Report (Test):\")\n",
        "print(classification_report(y_test, y_test_pred, target_names=[\"Class 0\", \"Class 1\"], zero_division=1))\n",
        "\n",
        "# שמירת המודל לקובץ לשימוש עתידי\n",
        "joblib.dump(classifier, 'other_cases_classifier.pkl')\n",
        "print(\"Model saved as 'other_cases_classifier.pkl'\")\n"
      ],
      "metadata": {
        "id": "uZPQX4-aKTJy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "K45l8LDFeChb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def export_model_errors(data, filename=\"model_errors.xlsx\"):\n",
        "    \"\"\"\n",
        "    Exports FP and FN errors to an Excel file with the document body and prediction probabilities.\n",
        "\n",
        "    Parameters:\n",
        "    - data (DataFrame): The DataFrame containing model predictions and probabilities.\n",
        "    - filename (str): The name of the output Excel file.\n",
        "\n",
        "    Returns:\n",
        "    - None\n",
        "    \"\"\"\n",
        "    # טבלת False Negatives: הערך בפועל 1 אך סווג כ-0\n",
        "    fn_table = data[(data[\"אחר\"] == 1) & (data[\"Prediction\"] == 0)][[\"גוף המסמך\", \"Prediction_Probability\"]]\n",
        "    fn_table[\"Error Type\"] = \"FN\"  # סוג הטעות\n",
        "\n",
        "    # טבלת False Positives: הערך בפועל 0 אך סווג כ-1\n",
        "    fp_table = data[(data[\"אחר\"] == 0) & (data[\"Prediction\"] == 1)][[\"גוף המסמך\", \"Prediction_Probability\"]]\n",
        "    fp_table[\"Error Type\"] = \"FP\"  # סוג הטעות\n",
        "\n",
        "    # איחוד הטבלאות\n",
        "    errors_table = pd.concat([fn_table, fp_table], ignore_index=True)\n",
        "\n",
        "\n",
        "    output_file = \"/content/drive/My Drive/Other_cases_classifiers_errors_only_TP_TN.xlsx\"  # עדכן את הנתיב לשמירת הקובץ\n",
        "    errors_table.to_excel(output_file, index=False)\n",
        "    print(f\"Combined file saved at: {output_file}\")\n",
        "\n",
        "export_model_errors(data, filename=\"model_errors.xlsx\")\n"
      ],
      "metadata": {
        "id": "lVvCnKIaLzPa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9MYsi0ibiu1c"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}